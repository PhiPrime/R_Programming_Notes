---
title: "R Programming"
author: "Coursera Course by John Hopkins University"
date: "INSTRUCTORS: Dr. Jeff Leek, Dr. Roger D. Peng, Dr. Brian Caffo"
fontsize: 11pt
output: 
  pdf_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
***
# Overview of R, R data types and objects, reading and writing data

## Installing R & RStudio
* This was covered in the [previous course](https://docs.google.com/document/d/12Co5sjoHIaxAcpTWHRSIs8APAqIlaoOVMFRdGCsMKU0/edit?usp=sharing).

## R-Markdown reference site  
* [I found a site that expands on some features of R-Markdown and have been referencing it pretty regularly](https://bookdown.org/yihui/rmarkdown/pdf-document.html)

## Swirl
* swirl teaches you R programming and data science interactively, at your own pace, and right in the R console.  
* Start swirl  
  + install the package "swirl" if you haven't yet  
  + Every time you want to run swirl execute:  
    - library("swirl")  
    - swirl()  
  + You'll then be prompted to install a course  
  + [Help page for swirl](https://swirlstats.com/help.html)  

## History of S and R programming
* What is S?  
  + R is a dialect of S  
  + S was developed by John Chambers and others at Bell Labs  
  + Initiated in 1976 as an internal statistical analysis environment, implemented as FORTRAN libraries
    - Early versions did not contain functions for statistical modeling  
  + Version 3 was released in 1988, which was rewritten in C and began to resemble the system that we have today.  
  + Version 4 was released in 1998 and is the version we use today.  
    - This version is documented in *Programming with Data* by John Chambers (the green book) 
  + Insightful sells its implementation of the S language under the name *S-PLUS*, which includes a number of fancy features, mostly GUIs. 
  + S won the Association for Computing Machinery's Software System Award in '98  
  + (More about S)[https://web.archive.org/web/20181014111802/ect.bell-labs.com/sl/S/]  

* What is R?  
  + R was developed by Ross Ihaka and Robert Gentleman, they documented their experience in a (1996 JCGS paper)[https://amstat.tandfonline.com/doi/abs/10.1080/10618600.1996.10474713].  
  + In 1995, R become free software after Martin Machler convinced Ross & Robert to use the GNU (General Public License)  
  + Versions  
    - R version 1.0.0 was released in 2000  
    - R version 3.0.2 is released in Dec. 2013  
  + Syntax is similar to S, making it easy for S-PLUS users to switch over  
  + Runs on almost any standard computing platform/OS (even on the PS3)  
  + Frequent releases; active development and communities  
  + Functionality is divided into modular packages as to keep it "lean"  
  + It's free!  
  + What is free about Free Software?  
    - Freedom 0: freedom to run the program, for any purpose  
    - Freedom 1: freedom to study how the program works, and adapt it to one's needs. Which implies access to the source code
    - Freedom 2: freedom to redistribute copies
    - Freedom 3: freedom to improve the program, and release your improvements to the public, or to sell them.
    - These are outlined by the (Free Software Foundation)[https://www.fsf.org/]  

* Drawbacks of R  
  + Essentially based on 40 year old technology,the original S language
  + Little build support for dynamic or 3D graphics. Although there are packages for such
  + Functionality is based on consumer demand and use contributions, if a feature is not present you'll have to build it.  
  + Objects that are manipulated in R have to be stored in the physical memory of the computer, as such if an object is bigger than the memory you'll be unable to load it into memory  
  + Not ideal for all possible situations, such as calling to order pizza (but this is a drawback of all software packages)  

*Design of the R System  
  + "base" R system that can be downloaded from (CRAN)[http://cran.r-project.org] (krey-an) which...  
    - contains the packages: **utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4**.  
    - and "Recommends" the packages: **boot, class, cluster, codetools, foreign, KernSmooth, lattice, mgcv, nlme, rpart, survival, MASS, spatial, nnet, Matrix**.  
  + Packages are available all around the web, but packages on CRAN have to meet a certain level of quality.  

* Some Useful Books on S/R  
  + Chambers (2008). *Software for Data Analysis*, Springer.    
  + Chambers (1998). *Programming with Data*, Springer.  
  + Venables & Ripley (2002). *Modern Applied Statistics with S*, Springer.  
  + Venables & Ripley (2000). *S Programming*, Springer.   
  + Pinheiro & Bates (2000). *Mixed-Effects Models in S and S-Plus*, Springer.  
  + Murrell (2005). *R Graphics*, Chapman & Hall/CRC Press.  
  + (Additional Books)[http://www.r-project.org/doc/bib/R-books.html]  

## Review of getting help
* [Covered in previous course](https://docs.google.com/document/d/12Co5sjoHIaxAcpTWHRSIs8APAqIlaoOVMFRdGCsMKU0/edit?usp=sharing)  

## Input and Evaluation: Vocabulary/Syntax

* **Expressions -** The code that is typed into the R prompt.  
* **Assignment Operator -** assigns a value to a symbol, Ex:  
```x <- 1```  
* *Output a variable*:  
```{r echo= TRUE}
x <- 36
print(x) ##explicit printing
## or one can just type the variable 
x ##auto-printing
```

* *Comment:* Use a Hash(#) symbol to make a comment to the right of #  
* *[1]* is indicating the following variable is the first element of the vector

```{r echo= TRUE}
x <- 1:30 ##Loads x with the numbers 1 to 30
print(x)
## here, [26] is telling you the next number is the 26th element of the vector
```

* `Inf` - represents infinity and can be used in ordinary calculations (Ex: 1 / `Inf` is 0)  
* `Nan` - represents an undefined value ("not a number") (Ex: 0/0 is `NaN`).  
  + Can also be thought of as a missing value  
* **Attributes -** Some objects in R come with attributes. These attributes can be set or modified with the expression `attributes()`. They are:  
  + names, dimnames (dimension names)
  + dimensions (e.g. matrices, arrays) - number of rows & cols, or more depending on dimensions of array
  + class - the data type of the object
  + length - number of elements
  + other user-defined attributes/metadata can be added  
* **Coercion -** occurs so that every element of a vector is of the same class (Covered further in Vector section)  



## Different atomic data types

* R has five basic, or "atomic", classes of objects:  
  + character  
    - In `R` there is no `string` data type. It is also considered part of the `character` data type
  + numeric (real numbers)  
    - R thinks as numbers as these by default  
  + integer  
    - Must be explicitly declared with the L suffix; `x <- 1` assigns a numeric object, but `x <- 1L` explicitly assigns an integer  
  + complex   
  + logical (True/False)  

* A vector can only contain objects of the same class  
  + an empty vector can be created with `vector()`  
* However, a **list** is represented as a vector but can contain objects of different classes (as such we usually use these)  

## Vectors, Lists, and Matrices   

* The `c()` function (can be thought to stand for "concatenate")  
  + Can be used to create vectors of objects  
```{r}
x <- c(0.5, 0.6) ## numeric
x <- c(TRUE, FALSE) ## logical
x <- c(T, F) ## logical
x <- c("a", "b", "c") ## character
x <- c(1+0i, 2+4i) ## complex
```
* The `vector()` function  
  + Can also be used to create, you guessed it, vectors  
```{r}
x <- vector() ## Creates an empty vector
x ## Prints as code that evaluates as FALSE

x <- vector(mode = "numeric", length = 10) 
## Creates a vector with length "10" of numeric data type,default value is 0
x

x <- vector("numeric", 5) 
##The parameter names are not required, but can easily clarify code
x
```
  + When different objects are mixed in a vector, **coercion** occurs so all objects are of the same class.  
    - R will implicitly create the "Least Common Denominator" of the mixed classes
```{r}
y <- c(1.7, "a") ## character
y

y <- c(TRUE, 2) ## numeric
y

y <- c("a", TRUE) ## character
y
y[2] ## "TRUE" is a string stored as a "character" data type
y[3] ## The third element does not exist
```
    
  + Objects can be **explicitly coerced** from one class to another using the `as.*` functions, if available.  
    - Nonsensical coercion results in `NA`s
```{r}
x <- 0:6
class(x)
as.numeric(x)
as.logical(x)
as.character(x)
as.complex(x)
x
y <- as.character(x)
y

x <- c("a", "b", "c")
as.numeric(x) ##Nonsensical coercion will also show a warning
as.logical(x)
as.complex(x)
```
    
* Lists (Important data type in R that you should get to know well)
  + Lists are a type of vector that can contain elements of different classes.
  + Doesn't print like a vector because every element is different
    - prints index of element with double brackets bordering it: `[[1]]`
```{r}
x <- list(1, "a", TRUE, 1 + 4i, 16 +18i)
x
```
  
* **Matrices -** a type of vector with a *dimension* attribute.  
  + The *dimension* attribute is itself an integer vector of length 2 (numRows, numCols)
  + Constructed *column-wise*, so entries can be thought of starting in the "upper left" corner, then running down the columns  
  + Matrices can also be created by adding a *dimension* attribute to an existing vector
```{r}
m <- matrix(nrow = 2, ncol = 3)
m
dim(m)##reports num of rows then cols
attributes(m) ## dim is an attribute of the vector
m <- matrix(1:6, 2, 3) ## Demonstrating column-wise filling of matrix
m

m <- 1:10 ## m is now just a vector
m

dim(m) <- c(2,5) ## adding the dimension attribute
m
```

  + Creating a matrix with **cbind** and **rbind**
    - cbind fills the columns with the elements of the vectors that are passed as the respective parameters
    - likewise, rbind fills the rows with the elements of the respective parameters
```{r}
x <- 1:3
y <- 10:12
cbind(x,y)
rbind(x,y)
```
    
## Other data types
* Factors  
  + Used to represent categorical data  
  + can be unordered or ordered
  + Kinda like enumerated data, where it's an integer at heart, and each integer has a *label*
  + Using factors with labels is *better* than using integers because factors are self-describing
    - consider "Male" and "Female" as opposed to just the values 1 and 2
  + Prints differently than a character value, does not include quotations and displays *Levels*
```{r}
x <- factor(c("yes", "yes", "no", "yes", "no"))
x
table(x) 
## displays a frequency table of the factors
unclass(x) 
## strips out the class and displays the underlying integer vector
```
  + The order of the levels can be set with the `levels` argument to `factor()`
    - This can be important in linear modelling because the first level is sued as the baseline level.
    - default levels are based alphabetically 
```{r}
x <- factor(
        c("yes", "yes", "no", "yes", "no"),
        levels = c("yes", "no")
        )
x
```
    
  
  
* Missing Values (`NA` or `NaN`)
  + `NaN` is for undefined mathematical operations
  + `is.na()` and `is.nan()` are logical tests for the respective missing values
  + `NA` values have a class also, so there are integer `NA`, character `NA`, etc.
  + a `NaN` is also a `NA`, however the converse is not true
```{r}
x <- c(1, 2, NA, 10, 3)
is.na(x)
is.nan(x)
x <- c(1, 2, NaN, NA, 4)
is.na(x)
is.nan(x)
```
  
  
* Data Frames
  + Used to store tabular data
  + Special type of list where every element has to have the same length
  + Each element is like a column and the length of each element is the number of rows
  + like lists, Data Frames can store different classes in each column
  + Attribute: `row.names`
    - Useful for annotating data
    - However, often the row names are not interesting and we use "1, 2, 3..."
  + Usually created by calling `read.table()` or `read.csv()`
  + Can be converted to a matrix with `data.matrix()`
    - Forces each object to be coerced
```{r}
x <- data.frame(foo = 1:4, bar = c(T, T, F, F))## cols are named here
x
nrow(x)
ncol(x)
row.names(x)

```

  
* Names Attribute, useful for writing readable code and self-describing objects
  + Any R object can have names
```{r}
x <- 1:3
names(x)## by default there are no names
names(x) <- c("foo", "bar", "norf")
x
names(x)

##Lists can also have names
x <- list(a=1, b=2, c=3) 
## here, names are assigned as list is established
x

## Matrices can also have names, called dimnames
m <- matrix(1:4, nrow = 2, ncol = 2)
m
dimnames(m) <- list(c("a", "b"), c("c", "d")) 
#First vector is rownames, second is colnames
m
```
  
## Reading Data  

### Tabular Data
* Functions for **reading** data into R  
  + `read.table`,`read.csv` - for reading tabular data 
    - most common  
    - reads in data that's organized into rows and cols
    - returns a data frame
  + `readLines`, for reading lines of a text file  
  + `source`, for reading in R code files (inverse of `dump`)  
  + `dget`, for reading in R code files (inverse of `dput`)  
  + `load`, for reading in saved workspaces  
  + `unserialize`, for reading single R objects in binary form  
* Functions for **writing** data from R to files
  + `write.table`  
  + `writeLines`  
  + `dump`  
  + `dput`  
  + `save`  
  + `serialize`  
* Arguments of `read.table` function
  + `file` - the name of a file or connection  
  + `header` - logical that indicates if the file has a header line  
  + `sep` - a string that indicates how the columns are separated (tokens)  
  + `colClasses` - a character vector that indicates the class (Data type) of each column  
  + `nrows`  
  + `comment.char` - character string that indicates the comment character (default is '#')  
  + `skip` - number of lines to skip from the beginning  
  + `stringsAsFactors` - (default = TRUE) should character variables be coded as factors?  
* Implicit actions `R` takes
```{r}
data <- read.table("foo.txt") 
## Header must not have a label for the row labels for R to implicitly determine them
data

```
  + Skips lines that begin with a #
  + figures out how many rows there are (and how much memory needs to be allocated)
  + figure what type of variable is in each column of the table.
    - Telling R all these things directly will make it run faster and more efficiently
* `read.csv` is identical to `read.table` except that the default separator is a comma
  - `.csv` files are common output from excel or other spreadsheet programs.

### Large Data-sets  
* Doing the following things will make your life easier and prevent R from "choking"
  + [Read the help page for read.table, which contains many hints](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/read.table)  
  + Make a rough calculation of the memory required to store your data-set. 
    - Say for example, you have a data frame with 1,500,000 rows and 120 columns (not *that* big), all of which are numeric data. To roughly calculate how much memory is required..  
    - 1,500,000 * 120 * 8 bytes/numeric = 1440000000 bytes  
    - 1440000000 bytes / $2^{20}$ bytes/MB = 1,373.29 MB  
    - 1,373.29 MB = 1.37 GB  
    - Rule of thumb is that you'll need twice the amount of RAM to be able to read in the data-set  
  + If the data-set is larger than the amount of RAM on your computer you can probably stop right here.
    - Type `free -k` in terminal to return amount of RAM in kilobytes (`-b` for bytes, `-m` for megabytes and `-g` for gigabytes)
  + Set `comment.char = ""` if there are no commented lines in your file.
  + Use the `colClasses` argument.
    - Specifying this option instead of using the default can make `read.table` run *MUCH* faster.
    - To use this option you have to know the class of each column in your data frame.
    - If all of the columns are of the same data type, for example "numeric", then you can just set `colClasses = "numeric"`
    - A quick and dirty way to figure out the classes of each column is to take a small sample and determine it from that.
```{r}
initial <- read.table("datatable.txt", nrows = 100)
classes <- sapply(initial, class)
classes 
##Coded file wrong, I'm not gonna fix it now, Boolean should have said "TRUE" or "FALSE"
tabAll <- read.table("datatable.txt", 
                     colClasses = classes)
```
  + Set `nrows` 
    - This doesn't make R run faster but it helps with memory usage. 
    - A mild overestimate is okay.
    - You can type `wc <filename>` in terminal to return the number of: lines, strings, characters; "lines" are the `nrows`.  

### Useful things to know about your system when using R with larger data-sets
  + How much memory is available  
    - Type `free -k` into terminal  
  + What other applications are in use  
    - Type `ps aux` in terminal  
  + Are there other users logged into the same system  
    - Type `w` in terminal (Note: `last` will report a history)  
  + What OS are you using  
    - Type `lsb_release -a` into terminal  
  + Is the OS 32 or 64 bit  
    - Type `lscpu`, listed under first two returns 
    - On a 64 bit system you'll generally be able to access more memory

### Textual Formats  
* Contains the metadata, such as classes of columns, making transferring data more efficient as the metadata doesn't need to be determined again.  
* Known as `dumping` and `dputing`.
* Edit-able, which in the case of corruption allows for a potential recovery.
* Textual formats can work much better with version control programs.
* Adhere to the "Unix philosophy", which is to store data as text
* *Downside:* The format is not very space-efficient and as such usually requires compression  
* `dput` will deparse an R object, and `dget` can read the data back in from a file
```{r}
y <- data.frame(a=1, b="a")
dput(y) ## If file is not specified the output is displayed in the console
dput(y, file = "y.R")
new.y <- dget("y.R")##dget retrieves the object from a file
new.y
```

* Multiple objects can be deparsed using the `dump` function, then read back in with `source`  
  + The parameter for `dump` is a character vector that contains characters for the names of the variables one wishes to dump
```{r}
x <- "foo"
y <- data.frame(a=1, b="a")
dump(c("x", "y"))
dump(c("x", "y"), file = "data.R")
rm(x, y) ## removes the variables
source("data.R") ## reconstructs y and x objects
y
x
```

### Connections (Interfaces to the outside world)
* Connections can be made to files or to other, more "exotic" things.  
  + `file` - opens a connection to a file  
  + `gzfile` - opens a connection to a file compressed with *gzip*.  
  + `bzfile` - opens a connection to a file compressed with *bzip2*.  
  + `url` - opens a connection to a webpage (in HTML format).  
* Arguments  
  + `description` is the name of the file  
  + `open` indicates how the file is opened
    - **"r" -** read only  
    - **"w" -** writing (and initializing a new file)  
    - **"a" -** appending  
    - **"rb", "wb", "ab" -** reading, writing, or appending in binary mode (Windows)  
    - There are other options but they aren't uber important  
* Connections are powerful tools that allow you to navigate files or other external objects in a more "sophisticated" way. 
  + However, one does not need to deal with the connection interface in many case    
```{r}
con <- file("foo.txt", "r")
data <- read.csv(con)
close(con)
```
  + ^This is the same as..  
```{r}
data <- read.csv("foo.txt")
```
  + As such, the connection was not necessary for this case
* Reading lines of a text file with `con` from a *gzip* file  
```{r}
con <- gzfile("words.gz")
x <- readLines(con, 10) ##reads in first 10 lines
x
```
  + `writeLines` takes a character vector and writes each element one line at a time to a text file  
* `readLines` can be used for reading in lines of webpages.  
```{r}
## This might take time
con <- url("http://www.jhsph.edu", "r") ##John Hopkin's School of Public Health
x <- readLines(con)
head(x) ##Displays the header
```

## Subsetting R objects using the "[", "[[", and "$" operators and logical vectors  

### Basics
* Operators to extract subsets of R objects
  + `[` always returns an object of the same class as the original
    - subsetting a vector will return a vector, a list will return a list, etc.
    - Can be used to select more than one element (there is one exception, when subsetting a single element from a matrix)
  + `[[` is used to extract elements of a *list* or *data frame*
    - Can only be used to extract a single element
    - The class of the returned object will not necessarily be a list or data frame
  + `$` is used to extract elements of a *list* or *data frame* by name
    - Similar to `[[` as it may not be of the same class
* Numerical Index for subsetting:
```{r}
x <- c("a", "b", "c", "c", "d", "a")
x[1] ## Returns first element
x[2] ## Returns second element
x[1:4] ## Returns first to fourth elements
x[c(2, 5)] ##Returns 2nd and 5th element
x[c(-2, -5)]##Returns everything EXCEPT the 2nd and 5th element
x[-c(2,5)]##Equivelent since the negative will multiply with every element of c(...)
x[2*c(1,3)]##Just like how this will actually be the 2nd and 6th element
```
* Logical Index for subsetting:
```{r}
x <- c("a", "b", "c", "c", "d", "a")
x[x > "a"]## returns all elements that are greater than "a"
u <- x > "a" 
## u is a logical vector that indicates which elements of x are greater than "a"
u
x[u] 
## subsets all elements of x such that u reports that index as TRUE; 
##elements that are > "a"
```


### Lists
* Lists can be subsetted with the `[[` or `$` operators
```{r}
x <- list(foo = 1:4, bar = 0.6)
x[1]
##Extracts the first element as a list, since the orginal set was a list class
x[[1]]##Extracts the first element as a sequence, not a list
x$bar ##returns the element that is associated with the name "bar"
x[["bar"]]##same as x$bar
x["bar"]##returns a list with the element "bar" in it
```
  + subsetting with the name is helpful when the index isn't known
* To extract multiple elements of a list, one must use the single bracket operator `[`
```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
x[c(1, 3)]##extracts the first and third element of the list
```
* The `[[` operator can be used with *computed* indices, whereas `$` can only be used with literal names.
```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
name <- "foo"
x[[name]] ## computed index for 'foo'
x$name ## element 'name' doesn't exist!
x$foo ## element 'foo' does exist
```
* The `[[` can also take an integer sequence instead of a single number
```{r}
x <- list(a = list(10, 12, 14), b = c(3.14, 2.81))
x[[c(1,3)]] 
##extracts first element, then the third element of said first element
x[[1]][[3]] ##equivelent
x[[c(2,1)]]##extracts first element of the second element of x
```


### Matrices  
* Subsetted as one would expect with (i,j) type indices.
```{r}
x <- matrix(1:6, 2, 3)
x
x[1,2] ##First row, second column
x[2,1] ##Second row, first column
```
* Indices can also be missing
```{r}
x[1,] ##Returns first row
x[,2] ##Returns second column
```
* By default, when a single element of a matrix is retrieved, it is returned as a vector of length 1 rather than a 1x1 matrix.
  + This is the exception of the `[` operator always returning the same class
  + This behavior can be turned off with the setting `drop = FALSE`.
```{r}
x <- matrix(1:6, 2, 3)
x[1,2] ##returns vector
x[1,2, drop = FALSE] ##returns a 1x1 matrix
```

* This transition of classes also holds when subsetting a single column or row  
```{r}
x <- matrix(1:6, 2, 3)
x[1,]
x[1, , drop = FALSE]
## the second parameter still has to be blank so the row is returned
```


### Partial Matching
* Allows one to not type out the full name of an element
  + Works with the `[[` and `$` operators  
```{r}
x <- list(aardvark = 1:5, baking = 1:10)
x$a 
##$ looks for a name that matches the "a", since aardvark 
##starts with an "a" that is returned
x[["a"]]
x[["a",exact = FALSE]]
## exact parameter has to be set to 
##false for the [[ to accept a partial match

y <- list(aardvark = 1:5, apples = 1:3)
y$a
y[["a", exact = FALSE]]
## Since there are two names that start with "a" the intended 
##element cannot be determined and NULL is returned
```


## Removing missing (NA) values from a vector
* A common operation that needs to be done IRL data
```{r}
x <- c(1, 2, NA, 4, NA, 5)
bad <- is.na(x) ## Creates a logical vector that is TRUE if the 
##element is missing, and FLASE if the element is not missing
x[!bad]##Logical is negated to get all the valid elements
```
* In the case of multiple things you want to take the subset of with no missing values
```{r}
x <- c(1, 2, NA, 4, NA, 5, NA, 7)
y <- c("a", "b", NA, "d", NA, "f", "g", NA)
good <- complete.cases(x,y)
##Indicates which elements of either vectors are missing
good
##As such, final two elements print FLASE since there is an NA 
##in at least one element
x[good]
y[good]
```

```{r}
airquality[1:6, ]## Returns first 6 rows
good <- complete.cases(airquality)
airquality[good, ][1:6, ]
##Returns first 6 rows that have don't have any missing values
```

* Additional note from `swirl()`
```{r}
my_data <- sample(c(rnorm(100), rep(NA,100)), 20)
my_data
is.na(my_data) 
## Returns a vector of logicals that indicate what positions of my_data are NA
my_data == NA 
## Returns a vector of NAs because NA is a placeholder for a qty that's 
##not available. Therefore the expression is incomplete and returns a 
##vector of NAs the same length as my_data
```


## Vectorized operations
* A feature of R that makes it easy to use on the command line
* Many operations in R are *vectorized* making code more efficient, concise, and easier to read.
```{r}
x <- 1:4; y <- 6:9
x + y ##Adds vectors by position of elements
x >=2 ##Returns a logical vector that indicates which vectors are > or = 2
y == 8
x * y ##Multiplies each element of x by the respective element of y
x / y ##Divides by element
```

* Vectorized Matrix Operations  
```{r}
x <- matrix(1:4, 2, 2); y <- matrix(rep(10,4), 2, 2)
x * y ##element-wise multiplication
x / y
x %*% y ## true matrix multiplication
```

### Stuff for quiz  
```{r}
##4
x <- 4L
class(x)#int?

##5
x <- c(4,TRUE)
class(x)

##6
x <- c(1,3,5)
y <- c(3,2,10)
rbind(x,y)

##8
x <- list(2, "a", "b", TRUE)
class(x[[1]])
x[[1]]

##9
x <- 1:4
y <- 2:3
x+y
class(x+y)
```


```{r}
##10
x <- c(3, 5, 1, 10, 12, 6)
ans <- c(0, 0, 0, 10, 12, 6)
x[x %in% 1:5] <- 0
x
```

```{r}
data <- read.csv("hw1_data.csv")
##First 2 rows
data[1:2,]

##Num rows
nrow(data)

#Extract final 2 rows
data[(nrow(data)-1):(nrow(data)),]

#Value of 47th row
data[47,]

#Number of missing Ozone
bad <-is.na(data[,1])
sum(bad)

##Mean of ozone without NA
cleanData <- data[!bad,1]
mean(cleanData)##mean of Ozone, ignore NA

##Find mean of Solar.R where Ozone values are > 31 & Temp values are >90
bigOzone <- (data[,1]>31)
bigTemp <-(data[,4]>90&!is.na(data[,4]))
sOnBig <- data[bigOzone&bigTemp, 2]
bad <- is.na(sOnBig)
cleanSolar <- sOnBig[!bad]
mean(cleanSolar)
```

```{r}
##What is the mean of "Temp" when "Month" is equal to 6
wheresSix <- (data[,5]==6)
sixMtemp <- data[wheresSix, 4]
mean(sixMtemp)
```

```{r}
##What was the maximum ozone value in month 5
wheresFive <- (data[,5]==5)
fivMonOz <- data[wheresFive, 1]
bad <- is.na(fivMonOz)
cleanFOzone <- fivMonOz[!bad]
max(cleanFOzone)
```

## Misc Vanilla Functions
*`dir.create()` - Creates a directory in current working directory (found with `getwd()`)  
*`args()` - Returns possible arguments of parameter  
*`file.<arguments>`  
  + exists - checks if parameter exists, returns logical
  + info - returns info about file; such as: size, if it is a directory, mode, mtime, ctime, atime, uid, gid, username, groupname.
* `dir.create` - allows to manipulate directories and file permissions
* *Sequence of Numbers*
  + The '`:`' operator  
```{r}
1:20
pi:10 ##Increments by 1 until number is > the upper limit, 10
15:1 ##Decrementing is cool too
```
  + `seq()`  
```{r}
seq(1,20) ##Equivelant to `1:20`
seq(0,10,by=0.5)
my_seq <- seq(5,10,length=30)##sets `by` so the inc is consistent
seq_along(my_seq)#Creates a seq from 1:length(my_seq)
```
  + `rep()` - creates a vector of a repeated value  
```{r}
rep(0, times = 30)
rep(c(0,1,2),times=10)##One can also use a vector as the argument
rep(c(0,1,2),each = 10)##Makes 10 of each
```
  
* `paste()` - joins elements of a vector
  + `collapse` - argument that tells R what character to add inbetween each element.  
```{r}
paste(1:3,c("X", "Y", "Z"), sep ="")#paste can also combine vectors
paste(1:8,c("X", "Y", "Z"), sep ="")#even of diferent length
```
  
* `rnorm()` - draws from a standard normal distribution, number drawn is determined by parameter  
```{r}
rnorm(10)
```
  
* `sample()` - takes a sample of the specified size from the elements of x; `replace` is a logical argument that can be included
```{r}
sample(c(1:20),10)
#`sample(c(1:5),10)` 
##^would cause an error since replace defaults to false and n is bigger than N
sample(c(1:5),10,replace=TRUE)
```

* `identical()` - logical return; TRUE if the two objects are **exactly** equal  
* A note on assigning names
```{r}
my_matrix <- matrix(1:20, 4, 5)##4x5 matrix
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)##NOughty!
my_data <- data.frame(patients, my_matrix)
my_data #The drake meme
```






















  
# Control structures, functions, scoping rules, dates and times
### Learning Objectives  
* Write an **[if-else](#if-else)** expression  
* Write a **[for loop](#for-loop)**, a **[while loop](#while-loop)**, and a **[repeat loop](#repeat-next-break)**
* Define a function in R and specify its return value(see **[Functions Part 1](#functions-pt-1)** and **[Functions Part 2](#functions-pt-2)**)  
* Describe **[how R binds a value to a symbol via the search list](#symbol-binding)**  
* Define what **[lexical scoping is](#lexical-scoping)** with respect to **[how the value of free variables are resolved in R](#free-variables)**  
* Describe the difference between **[lexical scoping and dynamic scoping rules](#scoping-rules-sub)**  
* Convert a character string representing a date/time into an **[R datetime object](#datetime-object)**. 
  
## Control Structures  
* Control structures allow you to control the flow of execution of the program
  + `if, else`: testing a condition  
  + `for`: execute a loop a fixed number of times  
  + `while`:execute a loop *while* a condition is true  
  + `repeat`: execute an infinite loop  
  + `break`: break the execution of a loop  
  + `next`: skip an interation of a loop  
  + `return`: exit a function  
* Infinite loops should generally be avoided, even if they are theoretically correct  
* For command-line interacte work, the *apply functions are more useful
  
  
### if-else  
* syntax can be just like `cpp`
```{r}
x <- sample(1:6, 1)
if(x>3){
  y <- 10
} else {
  y <- 0
}
vals <- c(x,y)
vals
```
* but `R` also excepts other syntax  
```{r}
x <- sample(1:6, 1)
y <- if(x>3){
  10
} else {
  0
}
vals <- c(x,y)
vals
```
* nested `if`s and "else-less" `if`s are also acceptable  

### for loop  
* `for` loops take an interator variable and assign it to successive values from a sequence or vector.
  + Common for iterating over the elements of an object
```{r}
for(i in 1:10){
  print(i)
}
```
  
* R is flexible in how you can index different objects; the following loops are all equivelent
```{r}
x <-  c("a", "b", "c", "d")

for(i in 1:4){
  print(x[i])
}

for (i in seq_along(x)) {##seq_along creates an integer sequence that's as long as x
  print(x[i])
}

for(letter in x) {##letter is assigned to the nth element of x
  print(letter)
}

for(i in 1:4) print(x[i])##{} can be omitted for a single element in the body
```
  
* Nested for loops are also acceptable  
  
### while loop  
```{r}
count <- 0
while(count < 10){
  print(count)
  count <- count + 1##Make sure you increment
}
```

*A while loop with logical operators
```{r}
z <- 5
while(z>=3 & z <= 10){
  print(z)
  coin <- rbinom(1,1,0.5)
  if(coin == 1){ ##random walk
    z <- z+1
  } else {
      z <- z-1
    }
}
```
* Conditionals will "**short circuit**" when evaluating `&` or `|`  

### Repeat, Next, Break
* Not common in statistical applications  
* only way to exit a `repeat` loop is to call `break`  

```{r}
x0 <- 1
tol <- 1e-8
count <- 0

repeat{
  count <- count + 1
  x1 <- sample(seq(-1,1,length.out = 1000), 1)
  
  if(abs(x1 - x0) < tol){
    outVect <- c("In ", count," loops we found a x0, ", x0, ", that was within ", tol, " of x1, ", x1)
    output <- paste(outVect, collapse = "")
    print(output)
    break
  } else {
    x0 <- x1
  }
}

```
  
* loops that are not guaranteed to stop ought to have a hard limit on the number of iterations(e.g. using a for loop instead) and then report whether convergence was achieved or not  

*`next` - used to skip an iteration of a loop
```{r}
for(i in 1:100){
  if(i <= 20){
    ##Skip the first 20 iterations
    next
  }
  ## Other code could go here
}
```

## Functions  
### Your first R function(s)
```{r}
add2 <- function(x, y) {
  x + y
}

add2(3,5)
```
```{r}
above10 <- function(x){
  use <- x > 10
  x[use]
}

above <- function(x, n = 10){##n value is defaulted to 10
  use <- x > n
  x[use]
}

y <- 1:20
above10(y)
above(y, 12)
```
```{r}
columnmean <- function(y, removeNA=TRUE) {
  nc <- ncol(y)
  means <- numeric(nc)##numeric vector, length same as value of nc
  for(i in 1:nc) {
    means[i] <-  mean(y[,i], na.rm = removeNA)##many functions have the option to remove NAs
  }
  means
}

columnmean(airquality)
columnmean(airquality, FALSE)
```
  
### Functions pt 1  
* created using the `function()` directive  
* stored as R objects, of the class "function".
* Function in R are "first class objects", as such..
  + they can be passed as arguments to other functions  
  + they can be nested, so that you can define a function inside of another function.
* The return value of a function is the last expression in the function body to be evaluated  
* Functions have **named arguments** whch potentially have **default values**  
  + The **formal arguments** are the arguments included in the function definition
  + The `formals` function returns a list of all the formal arguments of a function
  + Not every function call in R makes use of all the formal arguments, they can be missing or have a default set.  
* R function arguments can be matched positionally or by name. 
  + So all the following calls to `sd` are equivalent  
```{r}
mydata <- rnorm(100)
sd(mydata)
sd(x = mydata)
sd(x = mydata, na.rm = FALSE)
sd(na.rm = FALSE, x = mydata)
sd(na.rm = FALSE, mydata)## when picking a position R fills to earliest, undeclared argument
```
  + Messing around with the order of the arguments can lead to confusion, as such it's not recommended  
  + Positional matching and matching by name can be mixed, which is helpful when functions have many arguments and one doesn't need them all, Ex:
```{r}
args(lm)
```
  + The following two calls are equivalent  
    - `lm(data = mydata, y - x, model = FALSE, subset = 1:100)`  
    - `lm( y~x, mydata, 1:100, model = FALSE, x=TRUE)`  
  + Second option is ideal way to mix and match since first 3 are gonna be specified by position  
  + Function arguments can also be **partially** matched by the following Order of operations:
    1. Check for exact match for a named argument  
    2. Check for a partial match  
    3. Check for a positional match  
  
### Functions pt 2  
* In addition to not specifying a defauly value, you can also set an argument value to `NULL`
```{r}
f <-function(a, b = 1, c = 2, d = NULL) {
  ##<super_rad_code.txt>
}
```
* Arguments to functions are evaluated **lazily**, so they are evaluated only as needed  
```{r}
f <- function(a,b) {
  a^2
}
f(2) ##b is not evaluated in the function, so an error does not occur

f <- function(a,b) {
  print(a)
  print(b)
}
tryCatch(f(45), error=function(e){print("Error in print(b) : argument \"b\" is missing, with no default")}) 
  ##The function is evaluated until print(b) tries to execute

```

* The "`...`" Argument  
  + `...` indicate a variable number of arguments that are usually passed on to other functions.  
  + Often used when extending another function and you don't want to copy the entire argument list of the og function  
```{r}
myplot <- function(x,y, type = "1", ...) {
  plot(x,y,type = type, ...)
}
```

  + Also used with Generic function so that extra arguments can be passed to methods (more on this later)
```{r}
mean
```
  + The `...` argument is also necessary when the number of arguments passed to the fucntion cannot be known in advance  
```{r}
args(paste)
args(cat)
```
  + Arguments that appear **after** `...` on the arguemnt list must be named explicitly and cannot be partially matched  
```{r}
paste( "a", "b", sep = ":")
paste( "a", "b", se = ":")##Attempt to partially match `sep`
```
  


## Scoping Rules  

### Symbol Binding  
* How does R decide what value to assign to a symbol in it's body?  
```{r}
lm <- function(x) {x*x} ##lm is already a function in the `stats` package
lm
```

* R searches through diffrent environments when attempting to bind a value to a symbol  
1. The global environment - which is your workspace in the Evironment pane  
  + iow, local variables are prioritized  
2. Namepaces of each of the packages- in order of the search list  
  + `search()` displays the search list  
```{r}
search()##.GlobalEnv is always [1]
```
* *base* package is always last in the search list
* User's can configure which packages get loaded, as such one cannot assume a set list of packages will be available.  
  + When a user loads a package with `library` the namespace gets put in `[2]` of the search (list) stack.  
* Note that R has separate namespaces for functions and non-functions  
  + So it's possible to have an object named `c` and a function named `c`  
  + However only once symbol can be named `c` in your `.GlobalEnv`  

* Scoping rules for R are the main feature that make it different from the original `S` language  
  + R uses *lexical scoping* or *static scoping*. A common alternative is *dynamic scoping*  
    - lexical scoping turns out to be particularly useful for simplifying statistical computations  
  + These rules determine how a value is associated with a free variable in a function  

### Free Variables  
* Consider the following,

```{r}
f <- function(x,y) {
  x^2 + y / z
}
```
  + This function has 2 formal arguments `x` and `y`. The additional symbol, `z`, is called a *free variable*.  
  + A **free variable** is neither a formal argument nor a local variable  

### Lexical Scoping  
  + *the values of free variables are searched for in the environment in which the function was defined*  

* What is an environment
  + An *environment* is a collection of (symbol, value) pairs, i.e. `x` is a symbol and `3.14` might be its value.  
  + Every environment has a parent environment; thus it is possible for an environment to have multiple "children"  
  + the only environment without a parent is the *empty environment*
  + **a closure* or *function closure** - A function that is associated with an environment  
    - Key to a lot of interesting operations in `R`  

* Searching for the value for a free variable  
  + Search starts in the environment in which a function was defined  
  + Then the search is dontinued in the *parent environment*  
  + The search continues down the sequence of parent environments until..
  + We hit the *top-level environment*; this is usually the global environment (workspace) or the namespace of a package.  
  + After the top-level env. the search continues down the search list until.. 
  + We hit the *empty environment*, at which point an error is thrown.  
* Other languages that support lexical scoping:  
  + Scheme  
  + Perl  
  + Python  
  + Common Lisp (**[all languages converge to Lisp](https://www.quora.com/Do-all-programming-languages-actually-converge-to-LISP)**)


### Scoping Rules (sub)  
* R's big sellin' point is that you can functions defined *inside other functions*  
  + Languages like `C` don't let you do this  
  + In this case, the environment in which a function is defined is the body of another function
  + As such, a function can return a function  
  
```{r}
make.power <-  function(n) {
  pow <-  function(x) {
    x^n
  }
  pow
}
## This function returns another function as is value
## Which allows us to create functions as follows
cube <- make.power(3)
square <- make.power(2)
cube(3)
square(3)
```

* How do you know what a function's environment is?
```{r}
ls(environment(cube)) ##Returns objects within environment that a function was defined
get("n", environment(cube)) ##Returns the value of "n" within the `cube` environment

ls(environment(square))
get("n", environment(square)) 
```

* Example of ***dynamic scoping***  
```{r}
y <- 10

f <- function(x) {
  y <- 2##assign new value to 2 within function's scope
  y^2 + g(x) ##2^2 + g(x)
}

g <- function(x) {
  x*y ## computes x*10, regardless if y got reassigned elsewhere
}

f(3) ## Computes (2^2 + 2*10) due to dynamic scoping that is simulated here
```

* When a  in the global environment and is subsequently *called* from the global enironment, then the defining environment and the calling environment are the same. This can give the illusion of dynamic scoping.
```{r}
g <- function(x) {
  a <- 3
  x+a+y
}
y <- 3
g(2)
```
* This occurs because GlobalEnv is always first in the search list, as such g is in the same environment as when we call it and `y` exists  

###Consequences of Lexical Scoping
* In R, all objects must be stored in memory  
* All functions must carry a pointer to their respective defining environment, which could be anywhere  
* In S-PLUS, free variables are always looked up in the global workspace, so everything can be stored on the disk because the "defining environment" of all functions is the same.

## Aside: Likelihood & Log-likelihood
* **[Notes are from this video](https://youtu.be/ScduwntrMzc)**  
* Probability review  
  + proportion of times a given outcome would occur in many trials.  
    - Iow, It is the long-term relative frequency  
  + P(weight between 32 and 34 grams | mean = 32 and std. deviation = 2.5)
  + Read as: "Probability of a weight between 32 and 34 grams, given that the mean is 32 and the standard deviation is 2.5"  
* Likelihood  
  + *likelihood* - describes the extent to which the sample provides support for any particular parameter value. Higher support corresponds to a higher value for the likelihood.  
  + Likelihood describes probability of distribution factors, such as mean or std. deviation  
```{r echo=FALSE}
theta <- 0.07
n <- 100
k <- 0:20
plot(k, dbinom(k,n,theta), type = "s", 
    ylab = "Probability", xlab = "Number of \"TRUE\" samples", main = 
    paste("Binomial probability distribution for n = 100, std.dev = ", theta*100, "%", 
          sep=""))
abline(v = 6, col = "cyan")##Adds a straight line to a plot
abline(v = 7, col = "cyan")##col = "cyan" so it looks red in dark mode 

theta <- 0.08
plot(k, dbinom(k,n,theta), type = "s",  
    ylab = "Probability", xlab = "Number of \"TRUE\" samples", main = 
    paste("Binomial probability distribution for n = 100, std.dev = ", theta*100, "%", 
          sep=""))
abline(v = 6, col = "cyan")
abline(v = 7, col = "cyan")
```
  + If a sample of 100 was taken and 6 people returned TRUE, which of the above models is more ***Likely***?  
  + Likelihood of either model is the probability at 6.  
  + A **likelihood function** provides a model for a fixed sample outcome.  
  + Individual likelihood values are *meaningless*  
  + Comparing two values, however, is *informative*  
  + As such we ussually discuss a **Likelihood Ratio** - L(theta[1];y) / L(theta[2];y)  
    - Suppose the following:
```{r}
L_Of_Theta_0.07 <- 0.152
L_Of_Theta_0.08 <- 0.123
Liklihood_Ratio <- function(a, b) {
  round(a/b, digits = 3)
}
Liklihood_Ratio(L_Of_Theta_0.07, L_Of_Theta_0.08)
```
```{r echo= FALSE}
c(paste("Thus, a population prevalence of 7% has ", Liklihood_Ratio(L_Of_Theta_0.07, L_Of_Theta_0.08),
      " times the support of", sep= ""), "a population prevalence of 8% (given our sample)")
```

  + **likelihood function** - for a given sample, it creates the likelihoods for all possible values of theta  
  
  + In summary, in ***likelihood functions***, *the mean* or *the standard deviation* is the parameter  
  
## Optimization
* Optimization routines in R, like `optim`, `nlm`, and `optimize` require you to pass a function, whose argument is a vector of parameters (e.g. a **[log-likelihood](#aside-likelihood-log-likelihood)**)  
* Optimization tries to find the *min* or *max* of a given function
  + An object function might depend on a host of other things besides its parameters (like *data*)  
* When writing software which does optimization, it may be desirable to allow the user to hold certain parameters fixed  
* *Note*: Optimization functions in R *minimize* functions, so you need to use the negative log-likelihood  

```{r}
make.NegLogLik <- function(data, fixed=c(FALSE,FALSE)) {
  params <- fixed
  function(p) {
    params[!fixed] <- p #Assigns p to whatever variable wasn't fixed
    mu <- params[1]
    sigma <- params[2]
    a <- -0.5*length(data)*log(2*pi*sigma^2)
    b <- -0.5*sum((data-mu)^2) / (sigma^2)
    -(a+b)
  }
}

set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NegLogLik(normals)
nLL
#<environment: ...> tells you the address of the pointer to the defining environment
ls(environment(nLL))##Lists Values in function's environment

optim(c(mu=0, sigma = 1), nLL)$par
##Returns estimates for mu&sigma by minimizing neg. liklihood

nLL <- make.NegLogLik(normals, c(FALSE, 2))##Fixing sigma to 2
optimize(nLL, c(-1, 3))$minimum

nLL <- make.NegLogLik(normals, c(1, FALSE))##Fixing mu to 1
optimize(nLL, c(1e-6, 10))$minimum
```
* `optimize` will only optimize a function with a single missing variable  
  + `optim` can optimize a function with more than one missing variable  
  
```{r}
##The following plots the sigma likelihood
nLL <- make.NegLogLik(normals, c(1, FALSE))
x <- seq(1.7, 1.9, len=100)
y <- sapply(x, nLL)
plot(x, exp(-(y - min(y))), type = "l", main = "Sigma likelihood")

##The following plots the mu likelihood
nLL <- make.NegLogLik(normals, c(FALSE, 2))
x <- seq(0.5, 1.5, len = 100)
y <- sapply(x, nLL)
plot(x, exp(-(y - min(y))), type = "l", main = "Mu likelihood")
```

* Objective function can be "built" which contain all of the necessary data for evaluating the function  
* No need to carry around long argument lists  
  + useful for interactive and exploratory work  
* Code can be simplified and cleaned up  

## Coding Standards  
* "Help make your code readable...just like it is with any other *style*, like your clothing, it's hard to get everyone to agree on one set of ideas. But there are some basic/minimal standards for coding `R`"  
1. Code should always be written with a text editor and saved as `.txt`  
  + Can be read by any basic editting program; makes code versatile  
  + RStudio saves code as text by default
2. Indent your code  
3. Limit the width of your code (80 columns)  
  + indents and column width can be editted in settings of RStudio  
  + these limits help promote clean code
4. Limit the length of individual functions
  + Each function ought to only do one activity
    - `readTheData` should read and return the data, NOT read the data, process it, fit a model, and then print an output.
  + Nice to read an entire function that is able to fit on one screen of the editor  
  + Helps when debugging  

## Dates and Times  
* Dates are represented by the `Date` class  
  + Stored internally as the number of days since 1970-01-01  
  + Can be coerced from a character string using the `as.Date()` function
  + When printed they default to converting back to a readable character string  
  + If `unclass`ed, they'll display the numeric value R is storing them as  
```{r}
x <- as.Date("1970-01-01")
x
unclass(x)
unclass(as.Date("1970-01-02"))##One day since origin
```
  
  
* Times are represented by the `POSIXct` or the `POSIXlt` class  
  + Stored internally as the number of seconds since 1970-01-01 
    - Negative times are also valid
  + `POSIXct` is just a very large integer; useful when one wants to store times in something like a data frame  
    - `c` for "concise"  
```{r}
x <- Sys.time()
x ## Already in `POSIXct` format
unclass(x)
#x$sec
##Throws: "Error in x$sec : $ operator is invalid for atomic vectors"
p <- as.POSIXlt(x) ##After this conversion sec can be extracted
p$sec
str(p)
```

    
  + `POSIXlt` is a list "underneath" and it stores meta data such as: the day of the week, day of the year, month, day of the month  
    - `l` for "list"  
```{r}
x <- Sys.time()
x
p <- as.POSIXlt(x)
names(unclass(p))
p$sec
```

  
* `strptime` function - lets you convert dates written in different formats into `POSIXlt`  
  + Check `?strptime` for details on the string formatting
```{r}
datestring <- c("January 10, 2012 10:40", "December 9, 2011 9:10")  
x <- strptime(datestring, "%B %d, %Y %H:%M")
x
class(x)
```

*Operations on Dates and Times
  + Some mathematical operations work (`+`, `-`, logicals (i.e. `==`, `<=`))  
  + You can't mix classes  
```{r}
x <- as.Date("2012-01-01")
y <- strptime("9 Jan 2011 11:34:21", "%d %b %Y %H:%M:%S")
#x-y ##Throws:
## Incompatible methods ("-.Date", "-.POSIXt") for "-"
## Error: non-numeric argument to binary operator
x <- as.POSIXlt(x)
x-y
```
  + Some generic functions that work on dates and times  
    - `weekdays`: returns the day of the week  
    - `months`: returns the month name  
    - `quarters`: returns the quarter number ("Q1", "Q2", "Q3", or "Q4")  

* Dates and Times classes keep track of *leap years*, *leap seconds*, *daylight savings*, and *time zones
```{r}
x <- as.Date("2012-03-01")
y <- as.Date("2012-02-28")
x-y

x <- as.POSIXct("2012-10-25 01:00:00")
y <- as.POSIXct("2012-10-25 06:00:00", tz = "GMT")
y-x
```
### Datetime Object
* Summary
  + Dates and times have special classes in R that allow for numerical and statistical calculations  
  + Dates use the `Date` class  
  + Times use the `POSIXct` and `POSIXlt` class  
  + Character strings can be coerced to date/Time classes using the `strptime`, `as.Date`, `as.POSIXlt`, or `as.POSIXct` functions.  
  + A lot of plotting functions will recognize Datetime objects  

## Misc Vanilla Functions  
* `rm(list=ls())` - clears everything from workspace  

* `&&` operator will only evaluate the first element of a vector and return a single logical; whereas `&` will evaluate all elements and return a logical vector  
  + likewise for the `||` and `|` operators  
* All `&` operators are evaluated before `|` operators  
* `xor()` evaluates arguments with *exclusive or*  
* `which()` returns a vector that indicates which indicies are `TRUE`  
* `any()` returns true if any element is true in the logical vector passed as an argument  
* `all()` returns true if all the elements in the logical vector passed as an argument are `TRUE`   
* *Note*: John Chambers, the creator of R once said:
  "*To understand computations in R, two slogans are helpful:* 
      1. *Everything that exists is an object.* 
      2. *Everything that happens is a function call.*"
* This is a strict rule in R programming: all arguments after an ellipses must have default values.  

* Let's say I wanted to define a binary operator that multiplied two numbers and then added one to the product. Notice the `%` and `"` surrounding the operator name. An implementation of that operator is below:
```{r}
 "%mult_add_one%" <- function(left, right){ # Notice the quotation marks!
   left * right + 1
 }

4 %mult_add_one% 5
```

### Testing out additional thangs  
```{r}
##2
x <- 1:10
#if(x > 5) { #returns error because only a condition of length 1 can be evaluated in an `if`
#  x <- 0
#}
```
```{r}
##3
f <- function(x) {
  g <- function(y) {
    y + z
  }
  z <- 4
  x + g(x)
}
```

```{r}
z <- 10
f(3)
##EO3
```









# Loop functions, debugging tools


# Simulation, code profiling
