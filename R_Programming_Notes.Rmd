---
title: "R Programming"
author: "Coursera Course by John Hopkins University"
date: "INSTRUCTORS: Dr. Jeff Leek, Dr. Roger D. Peng, Dr. Brian Caffo"
fontsize: 11pt
output: 
  pdf_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
***
# Overview of R, R data types and objects, reading and writing data

## Installing R & RStudio
* This was covered in the [previous course](https://docs.google.com/document/d/12Co5sjoHIaxAcpTWHRSIs8APAqIlaoOVMFRdGCsMKU0/edit?usp=sharing).

## R-Markdown reference site  
* [I found a site that expands on some features of R-Markdown and have been referencing it pretty regularly](https://bookdown.org/yihui/rmarkdown/pdf-document.html)

## Swirl
* swirl teaches you R programming and data science interactively, at your own pace, and right in the R console.  
* Start swirl  
  + install the package "swirl" if you haven't yet  
  + Every time you want to run swirl execute:  
    - library("swirl")  
    - swirl()  
  + You'll then be prompted to install a course  
  + [Help page for swirl](https://swirlstats.com/help.html)  

## History of S and R programming
* What is S?  
  + R is a dialect of S  
  + S was developed by John Chambers and others at Bell Labs  
  + Initiated in 1976 as an internal statistical analysis environment, implemented as FORTRAN libraries
    - Early versions did not contain functions for statistical modeling  
  + Version 3 was released in 1988, which was rewritten in C and began to resemble the system that we have today.  
  + Version 4 was released in 1998 and is the version we use today.  
    - This version is documented in *Programming with Data* by John Chambers (the green book) 
  + Insightful sells its implementation of the S language under the name *S-PLUS*, which includes a number of fancy features, mostly GUIs. 
  + S won the Association for Computing Machinery's Software System Award in '98  
  + (More about S)[https://web.archive.org/web/20181014111802/ect.bell-labs.com/sl/S/]  

* What is R?  
  + R was developed by Ross Ihaka and Robert Gentleman, they documented their experience in a (1996 JCGS paper)[https://amstat.tandfonline.com/doi/abs/10.1080/10618600.1996.10474713].  
  + In 1995, R become free software after Martin Machler convinced Ross & Robert to use the GNU (General Public License)  
  + Versions  
    - R version 1.0.0 was released in 2000  
    - R version 3.0.2 is released in Dec. 2013  
  + Syntax is similar to S, making it easy for S-PLUS users to switch over  
  + Runs on almost any standard computing platform/OS (even on the PS3)  
  + Frequent releases; active development and communities  
  + Functionality is divided into modular packages as to keep it "lean"  
  + It's free!  
  + What is free about Free Software?  
    - Freedom 0: freedom to run the program, for any purpose  
    - Freedom 1: freedom to study how the program works, and adapt it to one's needs. Which implies access to the source code
    - Freedom 2: freedom to redistribute copies
    - Freedom 3: freedom to improve the program, and release your improvements to the public, or to sell them.
    - These are outlined by the (Free Software Foundation)[https://www.fsf.org/]  

* Drawbacks of R  
  + Essentially based on 40 year old technology,the original S language
  + Little build support for dynamic or 3D graphics. Although there are packages for such
  + Functionality is based on consumer demand and use contributions, if a feature is not present you'll have to build it.  
  + Objects that are manipulated in R have to be stored in the physical memory of the computer, as such if an object is bigger than the memory you'll be unable to load it into memory  
  + Not ideal for all possible situations, such as calling to order pizza (but this is a drawback of all software packages)  

*Design of the R System  
  + "base" R system that can be downloaded from (CRAN)[http://cran.r-project.org] (krey-an) which...  
    - contains the packages: **utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4**.  
    - and "Recommends" the packages: **boot, class, cluster, codetools, foreign, KernSmooth, lattice, mgcv, nlme, rpart, survival, MASS, spatial, nnet, Matrix**.  
  + Packages are available all around the web, but packages on CRAN have to meet a certain level of quality.  

* Some Useful Books on S/R  
  + Chambers (2008). *Software for Data Analysis*, Springer.    
  + Chambers (1998). *Programming with Data*, Springer.  
  + Venables & Ripley (2002). *Modern Applied Statistics with S*, Springer.  
  + Venables & Ripley (2000). *S Programming*, Springer.   
  + Pinheiro & Bates (2000). *Mixed-Effects Models in S and S-Plus*, Springer.  
  + Murrell (2005). *R Graphics*, Chapman & Hall/CRC Press.  
  + (Additional Books)[http://www.r-project.org/doc/bib/R-books.html]  

## Review of getting help
* [Covered in previous course](https://docs.google.com/document/d/12Co5sjoHIaxAcpTWHRSIs8APAqIlaoOVMFRdGCsMKU0/edit?usp=sharing)  

## Input and Evaluation: Vocabulary/Syntax

* **Expressions -** The code that is typed into the R prompt.  
* **Assignment Operator -** assigns a value to a symbol, Ex:  
```x <- 1```  
* *Output a variable*:  
```{r echo= TRUE}
x <- 36
print(x) ##explicit printing
## or one can just type the variable 
x ##auto-printing
```

* *Comment:* Use a Hash(#) symbol to make a comment to the right of #  
* *[1]* is indicating the following variable is the first element of the vector

```{r echo= TRUE}
x <- 1:30 ##Loads x with the numbers 1 to 30
print(x)
## here, [26] is telling you the next number is the 26th element of the vector
```

* `Inf` - represents infinity and can be used in ordinary calculations (Ex: 1 / `Inf` is 0)  
* `Nan` - represents an undefined value ("not a number") (Ex: 0/0 is `NaN`).  
  + Can also be thought of as a missing value  
* **Attributes -** Some objects in R come with attributes. These attributes can be set or modified with the expression `attributes()`. They are:  
  + names, dimnames (dimension names)
  + dimensions (e.g. matrices, arrays) - number of rows & cols, or more depending on dimensions of array
  + class - the data type of the object
  + length - number of elements
  + other user-defined attributes/metadata can be added  
* **Coercion -** occurs so that every element of a vector is of the same class (Covered further in Vector section)  



## Different atomic data types

* R has five basic, or "atomic", classes of objects:  
  + character  
    - In `R` there is no `string` data type. It is also considered part of the `character` data type
  + numeric (real numbers)  
    - R thinks as numbers as these by default  
  + integer  
    - Must be explicitly declared with the L suffix; `x <- 1` assigns a numeric object, but `x <- 1L` explicitly assigns an integer  
  + complex   
  + logical (True/False)  

* A vector can only contain objects of the same class  
  + an empty vector can be created with `vector()`  
* However, a **list** is represented as a vector but can contain objects of different classes (as such we usually use these)  

## Vectors, Lists, and Matrices   

* The `c()` function (can be thought to stand for "concatenate")  
  + Can be used to create vectors of objects  
```{r}
x <- c(0.5, 0.6) ## numeric
x <- c(TRUE, FALSE) ## logical
x <- c(T, F) ## logical
x <- c("a", "b", "c") ## character
x <- c(1+0i, 2+4i) ## complex
```
* The `vector()` function  
  + Can also be used to create, you guessed it, vectors  
```{r}
x <- vector() ## Creates an empty vector
x ## Prints as code that evaluates as FALSE

x <- vector(mode = "numeric", length = 10) 
## Creates a vector with length "10" of numeric data type,default value is 0
x

x <- vector("numeric", 5) 
##The parameter names are not required, but can easily clarify code
x
```
  + When different objects are mixed in a vector, **coercion** occurs so all objects are of the same class.  
    - R will implicitly create the "Least Common Denominator" of the mixed classes
```{r}
y <- c(1.7, "a") ## character
y

y <- c(TRUE, 2) ## numeric
y

y <- c("a", TRUE) ## character
y
y[2] ## "TRUE" is a string stored as a "character" data type
y[3] ## The third element does not exist
```
    
  + Objects can be **explicitly coerced** from one class to another using the `as.*` functions, if available.  
    - Nonsensical coercion results in `NA`s
```{r}
x <- 0:6
class(x)
as.numeric(x)
as.logical(x)
as.character(x)
as.complex(x)
x
y <- as.character(x)
y

x <- c("a", "b", "c")
as.numeric(x) ##Nonsensical coercion will also show a warning
as.logical(x)
as.complex(x)
```
    
* Lists (Important data type in R that you should get to know well)
  + Lists are a type of vector that can contain elements of different classes.
  + Doesn't print like a vector because every element is different
    - prints index of element with double brackets bordering it: `[[1]]`
```{r}
x <- list(1, "a", TRUE, 1 + 4i, 16 +18i)
x
```
  
* **Matrices -** a type of vector with a *dimension* attribute.  
  + The *dimension* attribute is itself an integer vector of length 2 (numRows, numCols)
  + Constructed *column-wise*, so entries can be thought of starting in the "upper left" corner, then running down the columns  
  + Matrices can also be created by adding a *dimension* attribute to an existing vector
```{r}
m <- matrix(nrow = 2, ncol = 3)
m
dim(m)##reports num of rows then cols
attributes(m) ## dim is an attribute of the vector
m <- matrix(1:6, 2, 3) ## Demonstrating column-wise filling of matrix
m

m <- 1:10 ## m is now just a vector
m

dim(m) <- c(2,5) ## adding the dimension attribute
m
```

  + Creating a matrix with **cbind** and **rbind**
    - cbind fills the columns with the elements of the vectors that are passed as the respective parameters
    - likewise, rbind fills the rows with the elements of the respective parameters
```{r}
x <- 1:3
y <- 10:12
cbind(x,y)
rbind(x,y)
```
    
## Other data types
* Factors  
  + Used to represent categorical data  
  + can be unordered or ordered
  + Kinda like enumerated data, where it's an integer at heart, and each integer has a *label*
  + Using factors with labels is *better* than using integers because factors are self-describing
    - consider "Male" and "Female" as opposed to just the values 1 and 2
  + Prints differently than a character value, does not include quotations and displays *Levels*
```{r}
x <- factor(c("yes", "yes", "no", "yes", "no"))
x
table(x) 
## displays a frequency table of the factors
unclass(x) 
## strips out the class and displays the underlying integer vector
```
  + The order of the levels can be set with the `levels` argument to `factor()`
    - This can be important in linear modelling because the first level is sued as the baseline level.
    - default levels are based alphabetically 
```{r}
x <- factor(
        c("yes", "yes", "no", "yes", "no"),
        levels = c("yes", "no")
        )
x
```
    
  
  
* Missing Values (`NA` or `NaN`)
  + `NaN` is for undefined mathematical operations
  + `is.na()` and `is.nan()` are logical tests for the respective missing values
  + `NA` values have a class also, so there are integer `NA`, character `NA`, etc.
  + a `NaN` is also a `NA`, however the converse is not true
```{r}
x <- c(1, 2, NA, 10, 3)
is.na(x)
is.nan(x)
x <- c(1, 2, NaN, NA, 4)
is.na(x)
is.nan(x)
```
  
  
* Data Frames
  + Used to store tabular data
  + Special type of list where every element has to have the same length
  + Each element is like a column and the length of each element is the number of rows
  + like lists, Data Frames can store different classes in each column
  + Attribute: `row.names`
    - Useful for annotating data
    - However, often the row names are not interesting and we use "1, 2, 3..."
  + Usually created by calling `read.table()` or `read.csv()`
  + Can be converted to a matrix with `data.matrix()`
    - Forces each object to be coerced
```{r}
x <- data.frame(foo = 1:4, bar = c(T, T, F, F))## cols are named here
x
nrow(x)
ncol(x)
row.names(x)

```

  
* Names Attribute, useful for writing readable code and self-describing objects
  + Any R object can have names
```{r}
x <- 1:3
names(x)## by default there are no names
names(x) <- c("foo", "bar", "norf")
x
names(x)

##Lists can also have names
x <- list(a=1, b=2, c=3) 
## here, names are assigned as list is established
x

## Matrices can also have names, called dimnames
m <- matrix(1:4, nrow = 2, ncol = 2)
m
dimnames(m) <- list(c("a", "b"), c("c", "d")) 
#First vector is rownames, second is colnames
m
```
  
## Reading Data  

### Tabular Data
* Functions for **reading** data into R  
  + `read.table`,`read.csv` - for reading tabular data 
    - most common  
    - reads in data that's organized into rows and cols
    - returns a data frame
  + `readLines`, for reading lines of a text file  
  + `source`, for reading in R code files (inverse of `dump`)  
  + `dget`, for reading in R code files (inverse of `dput`)  
  + `load`, for reading in saved workspaces  
  + `unserialize`, for reading single R objects in binary form  
* Functions for **writing** data from R to files
  + `write.table`  
  + `writeLines`  
  + `dump`  
  + `dput`  
  + `save`  
  + `serialize`  
* Arguments of `read.table` function
  + `file` - the name of a file or connection  
  + `header` - logical that indicates if the file has a header line  
  + `sep` - a string that indicates how the columns are separated (tokens)  
  + `colClasses` - a character vector that indicates the class (Data type) of each column  
  + `nrows`  
  + `comment.char` - character string that indicates the comment character (default is '#')  
  + `skip` - number of lines to skip from the beginning  
  + `stringsAsFactors` - (default = TRUE) should character variables be coded as factors?  
* Implicit actions `R` takes
```{r}
data <- read.table("foo.txt") 
## Header must not have a label for the row labels for R to implicitly determine them
data

```
  + Skips lines that begin with a #
  + figures out how many rows there are (and how much memory needs to be allocated)
  + figure what type of variable is in each column of the table.
    - Telling R all these things directly will make it run faster and more efficiently
* `read.csv` is identical to `read.table` except that the default separator is a comma
  - `.csv` files are common output from excel or other spreadsheet programs.

### Large Data-sets  
* Doing the following things will make your life easier and prevent R from "choking"
  + [Read the help page for read.table, which contains many hints](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/read.table)  
  + Make a rough calculation of the memory required to store your data-set. 
    - Say for example, you have a data frame with 1,500,000 rows and 120 columns (not *that* big), all of which are numeric data. To roughly calculate how much memory is required..  
    - 1,500,000 * 120 * 8 bytes/numeric = 1440000000 bytes  
    - 1440000000 bytes / $2^{20}$ bytes/MB = 1,373.29 MB  
    - 1,373.29 MB = 1.37 GB  
    - Rule of thumb is that you'll need twice the amount of RAM to be able to read in the data-set  
  + If the data-set is larger than the amount of RAM on your computer you can probably stop right here.
    - Type `free -k` in terminal to return amount of RAM in kilobytes (`-b` for bytes, `-m` for megabytes and `-g` for gigabytes)
  + Set `comment.char = ""` if there are no commented lines in your file.
  + Use the `colClasses` argument.
    - Specifying this option instead of using the default can make `read.table` run *MUCH* faster.
    - To use this option you have to know the class of each column in your data frame.
    - If all of the columns are of the same data type, for example "numeric", then you can just set `colClasses = "numeric"`
    - A quick and dirty way to figure out the classes of each column is to take a small sample and determine it from that.
```{r}
initial <- read.table("datatable.txt", nrows = 100)
classes <- sapply(initial, class)
classes 
##Coded file wrong, I'm not gonna fix it now, Boolean should have said "TRUE" or "FALSE"
tabAll <- read.table("datatable.txt", 
                     colClasses = classes)
```
  + Set `nrows` 
    - This doesn't make R run faster but it helps with memory usage. 
    - A mild overestimate is okay.
    - You can type `wc <filename>` in terminal to return the number of: lines, strings, characters; "lines" are the `nrows`.  

### Useful things to know about your system when using R with larger data-sets
  + How much memory is available  
    - Type `free -k` into terminal  
  + What other applications are in use  
    - Type `ps aux` in terminal  
  + Are there other users logged into the same system  
    - Type `w` in terminal (Note: `last` will report a history)  
  + What OS are you using  
    - Type `lsb_release -a` into terminal  
  + Is the OS 32 or 64 bit  
    - Type `lscpu`, listed under first two returns 
    - On a 64 bit system you'll generally be able to access more memory

### Textual Formats  
* Contains the metadata, such as classes of columns, making transferring data more efficient as the metadata doesn't need to be determined again.  
* Known as `dumping` and `dputing`.
* Edit-able, which in the case of corruption allows for a potential recovery.
* Textual formats can work much better with version control programs.
* Adhere to the "Unix philosophy", which is to store data as text
* *Downside:* The format is not very space-efficient and as such usually requires compression  
* `dput` will deparse an R object, and `dget` can read the data back in from a file
```{r}
y <- data.frame(a=1, b="a")
dput(y) ## If file is not specified the output is displayed in the console
dput(y, file = "y.R")
new.y <- dget("y.R")##dget retrieves the object from a file
new.y
```

* Multiple objects can be deparsed using the `dump` function, then read back in with `source`  
  + The parameter for `dump` is a character vector that contains characters for the names of the variables one wishes to dump
```{r}
x <- "foo"
y <- data.frame(a=1, b="a")
dump(c("x", "y"))
dump(c("x", "y"), file = "data.R")
rm(x, y) ## removes the variables
source("data.R") ## reconstructs y and x objects
y
x
```

### Connections (Interfaces to the outside world)
* Connections can be made to files or to other, more "exotic" things.  
  + `file` - opens a connection to a file  
  + `gzfile` - opens a connection to a file compressed with *gzip*.  
  + `bzfile` - opens a connection to a file compressed with *bzip2*.  
  + `url` - opens a connection to a webpage (in HTML format).  
* Arguments  
  + `description` is the name of the file  
  + `open` indicates how the file is opened
    - **"r" -** read only  
    - **"w" -** writing (and initializing a new file)  
    - **"a" -** appending  
    - **"rb", "wb", "ab" -** reading, writing, or appending in binary mode (Windows)  
    - There are other options but they aren't uber important  
* Connections are powerful tools that allow you to navigate files or other external objects in a more "sophisticated" way. 
  + However, one does not need to deal with the connection interface in many case    
```{r}
con <- file("foo.txt", "r")
data <- read.csv(con)
close(con)
```
  + ^This is the same as..  
```{r}
data <- read.csv("foo.txt")
```
  + As such, the connection was not necessary for this case
* Reading lines of a text file with `con` from a *gzip* file  
```{r}
con <- gzfile("words.gz")
x <- readLines(con, 10) ##reads in first 10 lines
x
```
  + `writeLines` takes a character vector and writes each element one line at a time to a text file  
* `readLines` can be used for reading in lines of webpages.  
```{r}
## This might take time
con <- url("http://www.jhsph.edu", "r") ##John Hopkin's School of Public Health
x <- readLines(con)
head(x) ##Displays the header
```

## Subsetting R objects using the "[", "[[", and "$" operators and logical vectors  

### Basics
* Operators to extract subsets of R objects
  + `[` always returns an object of the same class as the original
    - subsetting a vector will return a vector, a list will return a list, etc.
    - Can be used to select more than one element (there is one exception, when subsetting a single element from a matrix)
  + `[[` is used to extract elements of a *list* or *data frame*
    - Can only be used to extract a single element
    - The class of the returned object will not necessarily be a list or data frame
  + `$` is used to extract elements of a *list* or *data frame* by name
    - Similar to `[[` as it may not be of the same class
* Numerical Index for subsetting:
```{r}
x <- c("a", "b", "c", "c", "d", "a")
x[1] ## Returns first element
x[2] ## Returns second element
x[1:4] ## Returns first to fourth elements
x[c(2, 5)] ##Returns 2nd and 5th element
x[c(-2, -5)]##Returns everything EXCEPT the 2nd and 5th element
x[-c(2,5)]##Equivelent since the negative will multiply with every element of c(...)
x[2*c(1,3)]##Just like how this will actually be the 2nd and 6th element
```
* Logical Index for subsetting:
```{r}
x <- c("a", "b", "c", "c", "d", "a")
x[x > "a"]## returns all elements that are greater than "a"
u <- x > "a" 
## u is a logical vector that indicates which elements of x are greater than "a"
u
x[u] 
## subsets all elements of x such that u reports that index as TRUE; 
##elements that are > "a"
```


### Lists
* Lists can be subsetted with the `[[` or `$` operators
```{r}
x <- list(foo = 1:4, bar = 0.6)
x[1]
##Extracts the first element as a list, since the orginal set was a list class
x[[1]]##Extracts the first element as a sequence, not a list
x$bar ##returns the element that is associated with the name "bar"
x[["bar"]]##same as x$bar
x["bar"]##returns a list with the element "bar" in it
```
  + subsetting with the name is helpful when the index isn't known
* To extract multiple elements of a list, one must use the single bracket operator `[`
```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
x[c(1, 3)]##extracts the first and third element of the list
```
* The `[[` operator can be used with *computed* indices, whereas `$` can only be used with literal names.
```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
name <- "foo"
x[[name]] ## computed index for 'foo'
x$name ## element 'name' doesn't exist!
x$foo ## element 'foo' does exist
```
* The `[[` can also take an integer sequence instead of a single number
```{r}
x <- list(a = list(10, 12, 14), b = c(3.14, 2.81))
x[[c(1,3)]] 
##extracts first element, then the third element of said first element
x[[1]][[3]] ##equivelent
x[[c(2,1)]]##extracts first element of the second element of x
```


### Matrices  
* Subsetted as one would expect with (i,j) type indices.
```{r}
x <- matrix(1:6, 2, 3)
x
x[1,2] ##First row, second column
x[2,1] ##Second row, first column
```
* Indices can also be missing
```{r}
x[1,] ##Returns first row
x[,2] ##Returns second column
```
* By default, when a single element of a matrix is retrieved, it is returned as a vector of length 1 rather than a 1x1 matrix.
  + This is the exception of the `[` operator always returning the same class
  + This behavior can be turned off with the setting `drop = FALSE`.
```{r}
x <- matrix(1:6, 2, 3)
x[1,2] ##returns vector
x[1,2, drop = FALSE] ##returns a 1x1 matrix
```

* This transition of classes also holds when subsetting a single column or row  
```{r}
x <- matrix(1:6, 2, 3)
x[1,]
x[1, , drop = FALSE]
## the second parameter still has to be blank so the row is returned
```


### Partial Matching
* Allows one to not type out the full name of an element
  + Works with the `[[` and `$` operators  
```{r}
x <- list(aardvark = 1:5, baking = 1:10)
x$a 
##$ looks for a name that matches the "a", since aardvark 
##starts with an "a" that is returned
x[["a"]]
x[["a",exact = FALSE]]
## exact parameter has to be set to 
##false for the [[ to accept a partial match

y <- list(aardvark = 1:5, apples = 1:3)
y$a
y[["a", exact = FALSE]]
## Since there are two names that start with "a" the intended 
##element cannot be determined and NULL is returned
```


## Removing missing (NA) values from a vector
* A common operation that needs to be done IRL data
```{r}
x <- c(1, 2, NA, 4, NA, 5)
bad <- is.na(x) ## Creates a logical vector that is TRUE if the 
##element is missing, and FLASE if the element is not missing
x[!bad]##Logical is negated to get all the valid elements
```
* In the case of multiple things you want to take the subset of with no missing values
```{r}
x <- c(1, 2, NA, 4, NA, 5, NA, 7)
y <- c("a", "b", NA, "d", NA, "f", "g", NA)
good <- complete.cases(x,y)
##Indicates which elements of either vectors are missing
good
##As such, final two elements print FLASE since there is an NA 
##in at least one element
x[good]
y[good]
```

```{r}
airquality[1:6, ]## Returns first 6 rows
good <- complete.cases(airquality)
airquality[good, ][1:6, ]
##Returns first 6 rows that have don't have any missing values
```

* Additional note from `swirl()`
```{r}
my_data <- sample(c(rnorm(100), rep(NA,100)), 20)
my_data
is.na(my_data) 
## Returns a vector of logicals that indicate what positions of my_data are NA
my_data == NA 
## Returns a vector of NAs because NA is a placeholder for a qty that's 
##not available. Therefore the expression is incomplete and returns a 
##vector of NAs the same length as my_data
```


## Vectorized operations
* A feature of R that makes it easy to use on the command line
* Many operations in R are *vectorized* making code more efficient, concise, and easier to read.
```{r}
x <- 1:4; y <- 6:9
x + y ##Adds vectors by position of elements
x >=2 ##Returns a logical vector that indicates which vectors are > or = 2
y == 8
x * y ##Multiplies each element of x by the respective element of y
x / y ##Divides by element
```

* Vectorized Matrix Operations  
```{r}
x <- matrix(1:4, 2, 2); y <- matrix(rep(10,4), 2, 2)
x * y ##element-wise multiplication
x / y
x %*% y ## true matrix multiplication
```

### Stuff for quiz  
```{r}
##4
x <- 4L
class(x)#int?

##5
x <- c(4,TRUE)
class(x)

##6
x <- c(1,3,5)
y <- c(3,2,10)
rbind(x,y)

##8
x <- list(2, "a", "b", TRUE)
class(x[[1]])
x[[1]]

##9
x <- 1:4
y <- 2:3
x+y
class(x+y)
```


```{r}
##10
x <- c(3, 5, 1, 10, 12, 6)
ans <- c(0, 0, 0, 10, 12, 6)
x[x %in% 1:5] <- 0
x
```

```{r}
data <- read.csv("hw1_data.csv")
##First 2 rows
data[1:2,]

##Num rows
nrow(data)

#Extract final 2 rows
data[(nrow(data)-1):(nrow(data)),]

#Value of 47th row
data[47,]

#Number of missing Ozone
bad <-is.na(data[,1])
sum(bad)

##Mean of ozone without NA
cleanData <- data[!bad,1]
mean(cleanData)##mean of Ozone, ignore NA

##Find mean of Solar.R where Ozone values are > 31 & Temp values are >90
bigOzone <- (data[,1]>31)
bigTemp <-(data[,4]>90&!is.na(data[,4]))
sOnBig <- data[bigOzone&bigTemp, 2]
bad <- is.na(sOnBig)
cleanSolar <- sOnBig[!bad]
mean(cleanSolar)
```

```{r}
##What is the mean of "Temp" when "Month" is equal to 6
wheresSix <- (data[,5]==6)
sixMtemp <- data[wheresSix, 4]
mean(sixMtemp)
```

```{r}
##What was the maximum ozone value in month 5
wheresFive <- (data[,5]==5)
fivMonOz <- data[wheresFive, 1]
bad <- is.na(fivMonOz)
cleanFOzone <- fivMonOz[!bad]
max(cleanFOzone)
```

## Misc Vanilla Functions
*`dir.create()` - Creates a directory in current working directory (found with `getwd()`)  
*`args()` - Returns possible arguments of parameter  
*`file.<arguments>`  
  + exists - checks if parameter exists, returns logical
  + info - returns info about file; such as: size, if it is a directory, mode, mtime, ctime, atime, uid, gid, username, groupname.
* `dir.create` - allows to manipulate directories and file permissions
* *Sequence of Numbers*
  + The '`:`' operator  
```{r}
1:20
pi:10 ##Increments by 1 until number is > the upper limit, 10
15:1 ##Decrementing is cool too
```
  + `seq()`  
```{r}
seq(1,20) ##Equivelant to `1:20`
seq(0,10,by=0.5)
my_seq <- seq(5,10,length=30)##sets `by` so the inc is consistent
seq_along(my_seq)#Creates a seq from 1:length(my_seq)
```
  + `rep()` - creates a vector of a repeated value  
```{r}
rep(0, times = 30)
rep(c(0,1,2),times=10)##One can also use a vector as the argument
rep(c(0,1,2),each = 10)##Makes 10 of each
```
  
* `paste()` - joins elements of a vector
  + `collapse` - argument that tells R what character to add inbetween each element.  
```{r}
paste(1:3,c("X", "Y", "Z"), sep ="")#paste can also combine vectors
paste(1:8,c("X", "Y", "Z"), sep ="")#even of diferent length
```
  
* `rnorm()` - draws from a standard normal distribution, number drawn is determined by parameter  
```{r}
rnorm(10)
```
  
* `sample()` - takes a sample of the specified size from the elements of x; `replace` is a logical argument that can be included
```{r}
sample(c(1:20),10)
#`sample(c(1:5),10)` 
##^would cause an error since replace defaults to false and n is bigger than N
sample(c(1:5),10,replace=TRUE)
```

* `identical()` - logical return; TRUE if the two objects are **exactly** equal  
* A note on assigning names
```{r}
my_matrix <- matrix(1:20, 4, 5)##4x5 matrix
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)##NOughty!
my_data <- data.frame(patients, my_matrix)
my_data #The drake meme
```


* `invisible(x)` would be used within a function to prevent implicit printing of a variable when the function is called from the cmd_line   



















  
# Control structures, functions, scoping rules, dates and times
### Learning Objectives  
* Write an **[if-else](#if-else)** expression  
* Write a **[for loop](#for-loop)**, a **[while loop](#while-loop)**, and a **[repeat loop](#repeat-next-break)**
* Define a function in R and specify its return value(see **[Functions Part 1](#functions-pt-1)** and **[Functions Part 2](#functions-pt-2)**)  
* Describe **[how R binds a value to a symbol via the search list](#symbol-binding)**  
* Define what **[lexical scoping is](#lexical-scoping)** with respect to **[how the value of free variables are resolved in R](#free-variables)**  
* Describe the difference between **[lexical scoping and dynamic scoping rules](#scoping-rules-sub)**  
* Convert a character string representing a date/time into an **[R datetime object](#datetime-object)**. 
  
## Control Structures  
* Control structures allow you to control the flow of execution of the program
  + `if, else`: testing a condition  
  + `for`: execute a loop a fixed number of times  
  + `while`:execute a loop *while* a condition is true  
  + `repeat`: execute an infinite loop  
  + `break`: break the execution of a loop  
  + `next`: skip an iteration of a loop  
  + `return`: exit a function  
* Infinite loops should generally be avoided, even if they are theoretically correct  
* For command-line interactive work, the *apply functions are more useful
  
  
### if-else  
* syntax can be just like `cpp`
```{r}
x <- sample(1:6, 1)
if(x>3){
  y <- 10
} else {
  y <- 0
}
vals <- c(x,y)
vals
```
* but `R` also excepts other syntax  
```{r}
x <- sample(1:6, 1)
y <- if(x>3){
  10
} else {
  0
}
vals <- c(x,y)
vals
```
* nested `if`s and "else-less" `if`s are also acceptable  

### for loop  
* `for` loops take an iterator variable and assign it to successive values from a sequence or vector.
  + Common for iterating over the elements of an object
```{r}
for(i in 1:10){
  print(i)
}
```
  
* R is flexible in how you can index different objects; the following loops are all equivalent
```{r}
x <-  c("a", "b", "c", "d")

for(i in 1:4){
  print(x[i])
}

for (i in seq_along(x)) {##seq_along creates an integer sequence that's as long as x
  print(x[i])
}

for(letter in x) {##letter is assigned to the nth element of x
  print(letter)
}

for(i in 1:4) print(x[i])##{} can be omitted for a single element in the body
```
  
* Nested for loops are also acceptable  
  
### while loop  
```{r}
count <- 0
while(count < 10){
  print(count)
  count <- count + 1##Make sure you increment
}
```

*A while loop with logical operators
```{r}
z <- 5
while(z>=3 & z <= 10){
  print(z)
  coin <- rbinom(1,1,0.5)
  if(coin == 1){ ##random walk
    z <- z+1
  } else {
      z <- z-1
    }
}
```
* Conditionals will "**short circuit**" when evaluating `&` or `|`  

### Repeat, Next, Break
* Not common in statistical applications  
* only way to exit a `repeat` loop is to call `break`  

```{r}
x0 <- 1
tol <- 1e-8
count <- 0

repeat{
  count <- count + 1
  x1 <- sample(seq(-1,1,length.out = 1000), 1)
  
  if(abs(x1 - x0) < tol){
    outVect <- c("In ", count," loops we found a x0, ", x0, ", that was within ", tol, " of x1, ", x1)
    output <- paste(outVect, collapse = "")
    print(output)
    break
  } else {
    x0 <- x1
  }
}

```
  
* loops that are not guaranteed to stop ought to have a hard limit on the number of iterations(e.g. using a for loop instead) and then report whether convergence was achieved or not  

*`next` - used to skip an iteration of a loop
```{r}
for(i in 1:100){
  if(i <= 20){
    ##Skip the first 20 iterations
    next
  }
  ## Other code could go here
}
```

## Functions  
### Your first R function(s)
```{r}
add2 <- function(x, y) {
  x + y
}

add2(3,5)
```
```{r}
above10 <- function(x){
  use <- x > 10
  x[use]
}

above <- function(x, n = 10){##n value is defaulted to 10
  use <- x > n
  x[use]
}

y <- 1:20
above10(y)
above(y, 12)
```
```{r}
columnmean <- function(y, removeNA=TRUE) {
  nc <- ncol(y)
  means <- numeric(nc)##numeric vector, length same as value of nc
  for(i in 1:nc) {
    means[i] <-  mean(y[,i], na.rm = removeNA)##many functions have the option to remove NAs
  }
  means
}

columnmean(airquality)
columnmean(airquality, FALSE)
```
  
### Functions pt 1  
* created using the `function()` directive  
* stored as R objects, of the class "function".
* Function in R are "first class objects", as such..
  + they can be passed as arguments to other functions  
  + they can be nested, so that you can define a function inside of another function.
* The return value of a function is the last expression in the function body to be evaluated  
* Functions have **named arguments** which potentially have **default values**  
  + The **formal arguments** are the arguments included in the function definition
  + The `formals` function returns a list of all the formal arguments of a function
  + Not every function call in R makes use of all the formal arguments, they can be missing or have a default set.  
* R function arguments can be matched position-ally or by name. 
  + So all the following calls to `sd` are equivalent  
```{r}
mydata <- rnorm(100)
sd(mydata)
sd(x = mydata)
sd(x = mydata, na.rm = FALSE)
sd(na.rm = FALSE, x = mydata)
sd(na.rm = FALSE, mydata)## when picking a position R fills to earliest, undeclared argument
```
  + Messing around with the order of the arguments can lead to confusion, as such it's not recommended  
  + Positional matching and matching by name can be mixed, which is helpful when functions have many arguments and one doesn't need them all, Ex:
```{r}
args(lm)
```
  + The following two calls are equivalent  
    - `lm(data = mydata, y - x, model = FALSE, subset = 1:100)`  
    - `lm( y~x, mydata, 1:100, model = FALSE, x=TRUE)`  
  + Second option is ideal way to mix and match since first 3 are gonna be specified by position  
  + Function arguments can also be **partially** matched by the following Order of operations:
    1. Check for exact match for a named argument  
    2. Check for a partial match  
    3. Check for a positional match  
  
### Functions pt 2  
* In addition to not specifying a default value, you can also set an argument value to `NULL`
```{r}
f <-function(a, b = 1, c = 2, d = NULL) {
  ##<super_rad_code.txt>
}
```
* Arguments to functions are evaluated **lazily**, so they are evaluated only as needed  
```{r}
f <- function(a,b) {
  a^2
}
f(2) ##b is not evaluated in the function, so an error does not occur

f <- function(a,b) {
  print(a)
  print(b)
}
tryCatch(f(45), error=function(e){print("Error in print(b) : argument \"b\" is missing, with no default")}) 
  ##The function is evaluated until print(b) tries to execute

```

* The "`...`" Argument  
  + `...` indicate a variable number of arguments that are usually passed on to other functions.  
  + Often used when extending another function and you don't want to copy the entire argument list of the og function  
```{r}
myplot <- function(x,y, type = "1", ...) {
  plot(x,y,type = type, ...)
}
```

  + Also used with Generic function so that extra arguments can be passed to methods (more on this later)
```{r}
mean
```
  + The `...` argument is also necessary when the number of arguments passed to the function cannot be known in advance  
```{r}
args(paste)
args(cat)
```
  + Arguments that appear **after** `...` on the argument list must be named explicitly and cannot be partially matched  
```{r}
paste( "a", "b", sep = ":")
paste( "a", "b", se = ":")##Attempt to partially match `sep`
```
  


## Scoping Rules  

### Symbol Binding  
* How does R decide what value to assign to a symbol in it's body?  
```{r}
lm <- function(x) {x*x} ##lm is already a function in the `stats` package
lm
```

* R searches through different environments when attempting to bind a value to a symbol  
1. The global environment - which is your workspace in the Environment pane  
  + iow, local variables are prioritized  
2. Namepaces of each of the packages- in order of the search list  
  + `search()` displays the search list  
```{r}
search()##.GlobalEnv is always [1]
```
* *base* package is always last in the search list
* User's can configure which packages get loaded, as such one cannot assume a set list of packages will be available.  
  + When a user loads a package with `library` the namespace gets put in `[2]` of the search (list) stack.  
* Note that R has separate namespaces for functions and non-functions  
  + So it's possible to have an object named `c` and a function named `c`  
  + However only once symbol can be named `c` in your `.GlobalEnv`  

* Scoping rules for R are the main feature that make it different from the original `S` language  
  + R uses *lexical scoping* or *static scoping*. A common alternative is *dynamic scoping*  
    - lexical scoping turns out to be particularly useful for simplifying statistical computations  
  + These rules determine how a value is associated with a free variable in a function  

### Free Variables  
* Consider the following,

```{r}
f <- function(x,y) {
  x^2 + y / z
}
```
  + This function has 2 formal arguments `x` and `y`. The additional symbol, `z`, is called a *free variable*.  
  + A **free variable** is neither a formal argument nor a local variable  

### Lexical Scoping  
  + *the values of free variables are searched for in the environment in which the function was defined*  

* What is an environment
  + An *environment* is a collection of (symbol, value) pairs, i.e. `x` is a symbol and `3.14` might be its value.  
  + Every environment has a parent environment; thus it is possible for an environment to have multiple "children"  
  + the only environment without a parent is the *empty environment*
  + **a closure* or *function closure** - A function that is associated with an environment  
    - Key to a lot of interesting operations in `R`  

* Searching for the value for a free variable  
  + Search starts in the environment in which a function was defined  
  + Then the search is continued in the *parent environment*  
  + The search continues down the sequence of parent environments until..
  + We hit the *top-level environment*; this is usually the global environment (workspace) or the namespace of a package.  
  + After the top-level env. the search continues down the search list until.. 
  + We hit the *empty environment*, at which point an error is thrown.  
* Other languages that support lexical scoping:  
  + Scheme  
  + Perl  
  + Python  
  + Common Lisp (**[all languages converge to Lisp](https://www.quora.com/Do-all-programming-languages-actually-converge-to-LISP)**)


### Scoping Rules (sub)  
* R's big sellin' point is that you can functions defined *inside other functions*  
  + Languages like `C` don't let you do this  
  + In this case, the environment in which a function is defined is the body of another function
  + As such, a function can return a function  
  
```{r}
make.power <-  function(n) {
  pow <-  function(x) {
    x^n
  }
  pow
}
## This function returns another function as is value
## Which allows us to create functions as follows
cube <- make.power(3)
square <- make.power(2)
cube(3)
square(3)
```

* How do you know what a function's environment is?
```{r}
ls(environment(cube)) ##Returns objects within environment that a function was defined
get("n", environment(cube)) ##Returns the value of "n" within the `cube` environment

ls(environment(square))
get("n", environment(square)) 
```

* Example of ***dynamic scoping***  
```{r}
y <- 10

f <- function(x) {
  y <- 2##assign new value to 2 within function's scope
  y^2 + g(x) ##2^2 + g(x)
}

g <- function(x) {
  x*y ## computes x*10, regardless if y got reassigned elsewhere
}

f(3) ## Computes (2^2 + 2*10) due to dynamic scoping that is simulated here
```

* When a  in the global environment and is subsequently *called* from the global environment, then the defining environment and the calling environment are the same. This can give the illusion of dynamic scoping.
```{r}
g <- function(x) {
  a <- 3
  x+a+y
}
y <- 3
g(2)
```
* This occurs because GlobalEnv is always first in the search list, as such g is in the same environment as when we call it and `y` exists  

###Consequences of Lexical Scoping
* In R, all objects must be stored in memory  
* All functions must carry a pointer to their respective defining environment, which could be anywhere  
* In S-PLUS, free variables are always looked up in the global workspace, so everything can be stored on the disk because the "defining environment" of all functions is the same.

## Aside: Likelihood & Log-likelihood
* **[Notes are from this video](https://youtu.be/ScduwntrMzc)**  
* Probability review  
  + proportion of times a given outcome would occur in many trials.  
    - Iow, It is the long-term relative frequency  
  + P(weight between 32 and 34 grams | mean = 32 and std. deviation = 2.5)
  + Read as: "Probability of a weight between 32 and 34 grams, given that the mean is 32 and the standard deviation is 2.5"  
* Likelihood  
  + *likelihood* - describes the extent to which the sample provides support for any particular parameter value. Higher support corresponds to a higher value for the likelihood.  
  + Likelihood describes probability of distribution factors, such as mean or std. deviation  
```{r echo=FALSE}
theta <- 0.07
n <- 100
k <- 0:20
plot(k, dbinom(k,n,theta), type = "s", 
    ylab = "Probability", xlab = "Number of \"TRUE\" samples", main = 
    paste("Binomial probability distribution for n = 100, std.dev = ", theta*100, "%", 
          sep=""))
abline(v = 6, col = "cyan")##Adds a straight line to a plot
abline(v = 7, col = "cyan")##col = "cyan" so it looks red in dark mode 

theta <- 0.08
plot(k, dbinom(k,n,theta), type = "s",  
    ylab = "Probability", xlab = "Number of \"TRUE\" samples", main = 
    paste("Binomial probability distribution for n = 100, std.dev = ", theta*100, "%", 
          sep=""))
abline(v = 6, col = "cyan")
abline(v = 7, col = "cyan")
```
  + If a sample of 100 was taken and 6 people returned TRUE, which of the above models is more ***Likely***?  
  + Likelihood of either model is the probability at 6.  
  + A **likelihood function** provides a model for a fixed sample outcome.  
  + Individual likelihood values are *meaningless*  
  + Comparing two values, however, is *informative*  
  + As such we usually discuss a **Likelihood Ratio** - L(theta[1];y) / L(theta[2];y)  
    - Suppose the following:
```{r}
L_Of_Theta_0.07 <- 0.152
L_Of_Theta_0.08 <- 0.123
Liklihood_Ratio <- function(a, b) {
  round(a/b, digits = 3)
}
Liklihood_Ratio(L_Of_Theta_0.07, L_Of_Theta_0.08)
```
```{r echo= FALSE}
c(paste("Thus, a population prevalence of 7% has ", Liklihood_Ratio(L_Of_Theta_0.07, L_Of_Theta_0.08),
      " times the support of", sep= ""), "a population prevalence of 8% (given our sample)")
```

  + **likelihood function** - for a given sample, it creates the likelihoods for all possible values of theta  
  
  + In summary, in ***likelihood functions***, *the mean* or *the standard deviation* is the parameter  
  
## Optimization
* Optimization routines in R, like `optim`, `nlm`, and `optimize` require you to pass a function, whose argument is a vector of parameters (e.g. a **[log-likelihood](#aside-likelihood-log-likelihood)**)  
* Optimization tries to find the *min* or *max* of a given function
  + An object function might depend on a host of other things besides its parameters (like *data*)  
* When writing software which does optimization, it may be desirable to allow the user to hold certain parameters fixed  
* *Note*: Optimization functions in R *minimize* functions, so you need to use the negative log-likelihood  

```{r}
make.NegLogLik <- function(data, fixed=c(FALSE,FALSE)) {
  params <- fixed
  function(p) {
    params[!fixed] <- p #Assigns p to whatever variable wasn't fixed
    mu <- params[1]
    sigma <- params[2]
    a <- -0.5*length(data)*log(2*pi*sigma^2)
    b <- -0.5*sum((data-mu)^2) / (sigma^2)
    -(a+b)
  }
}

set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NegLogLik(normals)
nLL
#<environment: ...> tells you the address of the pointer to the defining environment
ls(environment(nLL))##Lists Values in function's environment

optim(c(mu=0, sigma = 1), nLL)$par
##Returns estimates for mu&sigma by minimizing neg. liklihood

nLL <- make.NegLogLik(normals, c(FALSE, 2))##Fixing sigma to 2
optimize(nLL, c(-1, 3))$minimum

nLL <- make.NegLogLik(normals, c(1, FALSE))##Fixing mu to 1
optimize(nLL, c(1e-6, 10))$minimum
```
* `optimize` will only optimize a function with a single missing variable  
  + `optim` can optimize a function with more than one missing variable  
  
```{r}
##The following plots the sigma likelihood
nLL <- make.NegLogLik(normals, c(1, FALSE))
x <- seq(1.7, 1.9, len=100)
y <- sapply(x, nLL)
plot(x, exp(-(y - min(y))), type = "l", main = "Sigma likelihood")

##The following plots the mu likelihood
nLL <- make.NegLogLik(normals, c(FALSE, 2))
x <- seq(0.5, 1.5, len = 100)
y <- sapply(x, nLL)
plot(x, exp(-(y - min(y))), type = "l", main = "Mu likelihood")
```

* Objective function can be "built" which contain all of the necessary data for evaluating the function  
* No need to carry around long argument lists  
  + useful for interactive and exploratory work  
* Code can be simplified and cleaned up  

## Coding Standards  
* "Help make your code readable...just like it is with any other *style*, like your clothing, it's hard to get everyone to agree on one set of ideas. But there are some basic/minimal standards for coding `R`"  
1. Code should always be written with a text editor and saved as `.txt`  
  + Can be read by any basic editing program; makes code versatile  
  + RStudio saves code as text by default
2. Indent your code  
3. Limit the width of your code (80 columns)  
  + indents and column width can be edited in settings of RStudio  
  + these limits help promote clean code
4. Limit the length of individual functions
  + Each function ought to only do one activity
    - `readTheData` should read and return the data, NOT read the data, process it, fit a model, and then print an output.
  + Nice to read an entire function that is able to fit on one screen of the editor  
  + Helps when debugging  

## Dates and Times  
* Dates are represented by the `Date` class  
  + Stored internally as the number of days since 1970-01-01  
  + Can be coerced from a character string using the `as.Date()` function
  + When printed they default to converting back to a readable character string  
  + If `unclass`ed, they'll display the numeric value R is storing them as  
```{r}
x <- as.Date("1970-01-01")
x
unclass(x)
unclass(as.Date("1970-01-02"))##One day since origin
```
  
  
* Times are represented by the `POSIXct` or the `POSIXlt` class  
  + Stored internally as the number of seconds since 1970-01-01 
    - Negative times are also valid
  + `POSIXct` is just a very large integer; useful when one wants to store times in something like a data frame  
    - `c` for "concise"  
```{r}
x <- Sys.time()
x ## Already in `POSIXct` format
unclass(x)
#x$sec
##Throws: "Error in x$sec : $ operator is invalid for atomic vectors"
p <- as.POSIXlt(x) ##After this conversion sec can be extracted
p$sec
str(p)
```

    
  + `POSIXlt` is a list "underneath" and it stores meta data such as: the day of the week, day of the year, month, day of the month  
    - `l` for "list"  
```{r}
x <- Sys.time()
x
p <- as.POSIXlt(x)
names(unclass(p)) 
p$sec
```

  
* `strptime` function - lets you convert dates written in different formats into `POSIXlt`  
  + Check `?strptime` for details on the string formatting
```{r}
datestring <- c("January 10, 2012 10:40", "December 9, 2011 9:10")  
x <- strptime(datestring, "%B %d, %Y %H:%M")
x
class(x)
```

*Operations on Dates and Times
  + Some mathematical operations work (`+`, `-`, logicals (i.e. `==`, `<=`))  
  + You can't mix classes  
```{r}
x <- as.Date("2012-01-01")
y <- strptime("9 Jan 2011 11:34:21", "%d %b %Y %H:%M:%S")
#x-y ##Throws:
## Incompatible methods ("-.Date", "-.POSIXt") for "-"
## Error: non-numeric argument to binary operator
x <- as.POSIXlt(x)
x-y
```
  + Some generic functions that work on dates and times  
    - `weekdays`: returns the day of the week  
    - `months`: returns the month name  
    - `quarters`: returns the quarter number ("Q1", "Q2", "Q3", or "Q4")  

* Dates and Times classes keep track of *leap years*, *leap seconds*, *daylight savings*, and *time zones
```{r}
x <- as.Date("2012-03-01")
y <- as.Date("2012-02-28")
x-y

x <- as.POSIXct("2012-10-25 01:00:00")
y <- as.POSIXct("2012-10-25 06:00:00", tz = "GMT")
y-x
```
### Datetime Object
* Summary
  + Dates and times have special classes in R that allow for numerical and statistical calculations  
  + Dates use the `Date` class  
  + Times use the `POSIXct` and `POSIXlt` class  
  + Character strings can be coerced to date/Time classes using the `strptime`, `as.Date`, `as.POSIXlt`, or `as.POSIXct` functions.  
  + A lot of plotting functions will recognize Datetime objects  

## Misc Vanilla Functions  
* `rm(list=ls())` - clears everything from workspace  

* `&&` operator will only evaluate the first element of a vector and return a single logical; whereas `&` will evaluate all elements and return a logical vector  
  + likewise for the `||` and `|` operators  
* All `&` operators are evaluated before `|` operators  
* `xor()` evaluates arguments with *exclusive or*  
* `which()` returns a vector that indicates which indices are `TRUE`  
* `any()` returns true if any element is true in the logical vector passed as an argument  
* `all()` returns true if all the elements in the logical vector passed as an argument are `TRUE`   
* *Note*: John Chambers, the creator of R once said:
  "*To understand computations in R, two slogans are helpful:* 
      1. *Everything that exists is an object.* 
      2. *Everything that happens is a function call.*"
* This is a strict rule in R programming: all arguments after an ellipses must have default values.  

* Let's say I wanted to define a binary operator that multiplied two numbers and then added one to the product. Notice the `%` and `"` surrounding the operator name. An implementation of that operator is below:
```{r}
 "%mult_add_one%" <- function(left, right){ # Notice the quotation marks!
   left * right + 1
 }

4 %mult_add_one% 5
```

* `rstudioapi::convertTheme(name)` will let you add a new theme

### Testing out additional thangs  
```{r}
##2
x <- 1:10
#if(x > 5) { #returns error because only a condition of length 1 can be evaluated in an `if`
#  x <- 0
#}
```
```{r}
##3
f <- function(x) {
  g <- function(y) {
    y + z
  }
  z <- 4
  x + g(x)
}
```

```{r}
z <- 10
f(3)
##EO3
```








# Loop functions, debugging tools

### Learning Objectives  
* Define **[an anonymous function](#anonymous-functions)** and 
**[describe its use in loop functions.](#lapply)**
* Describe **[how to start the R debugger](#debugging-tools)** 
for an arbitrary R function.
* Describe what **[the traceback() function does](#traceback)** and what is 
**[the function stack call](#function-stack-call)**

## Loop Functions
* Loop Functions allow you to execute a loop over an object or set of objects and keep compact, as to work on the command line; these functions then to have `apply` in them.  
* Overview  
  + 
### lapply
* Loop over a list and evaluate a function on each element  
* Takes three arguments: 1) a list `x` (Or it'll be coerced to a list using `as.list`)
```{r}
lapply
```
* `lapply` always returns a list, regardless of the class of the input  
```{r}
x <- list(a=1:5, b= rnorm(10))
lapply(x,mean)
```

* Each element of the list is a numeric vector and what returns is a vector with a single element  
```{r}
x <- list(a= 1:4, b = rnorm(10), c = rnorm(20,1), d = rnorm(100,5))
lapply(x, mean)
```

* Here `runif` is called, which creates a uniformed list of uniform random variables. The first argument determines how many variables to return (`runif(2)` will return a vector of length 2)  
```{r}
x <- 1:4
lapply(x, runif)

##Now specify the defaults of runif with lapply
lapply(x, runif, min = 0, max = 10)
```

###Anonymous Functions  
* functions that aren't assigned a name, but are generated "on the fly"  
```{r}
x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2))
x

##Use lapply and an Anon Function to extract the first column of each matrix
lapply(x, function(elt) elt[,1])
```


### sapply
* Variant of `lapply` that trys to simplify the result 
  + If the result is a list where every element's length is 1, then a vector is returned  
  + If the result is a list where every element is a vector of the same length (>1), a matrix is returned.
  + `else` case is to just return a list  
```{r}
x <- list(a = 1:4, b = rnorm(10), c = rnorm(20,1), d = rnorm(100, 5))
lapply(x, mean)
sapply(x, mean)##Returns vector with 4 numbers
```


### apply  
* Apply a function (often an anon one)over the margins of an array  
  + Occasionally you'll hear in the wil' that `apply` is better or faster than a for loop. This ain't true at all in R, but was in ol' versions of S
  + It is most often used to apply a function to the rows or columns of a matrix
  + Involves less typing
    - Less typing is always better because good programmers are alzy
* Arguments  
```{r}
str(apply)
```
  + `X` is an array
  + `MARGIN` is an integer vector indicating which margins should be "retained".  
  + `FUN` is a function to be applied  
  + ... is for other arguments to be passed to `FUN`  

* Examples  
```{r}
x <- matrix(rnorm(200), 20, 10)
apply(x, 2, mean)##Keep second dimension, columns
apply(x, 1, sum)##Takes sum over all the rows
```
 * For sums and means of matrix dimensions, we use the following shortcuts:
  + `rowSums` = `apply(x, 1, sum)`  
  + `rowMeans` = `apply(x, 1, mean)`  
  + `colSums` = `apply(x, 2, sum)`  
  + `colMeans` = `apply(x, 2, mean)`  
  + These shortcut functions are *much faster*, but one won't notice unless they're using a large matrix.  
  
```{r}
x <- matrix(rnorm(200), 20, 10)
apply(x,1, quantile, probs = c(0.25, 0.75)) 
#Returns 25th and 7th percentile for each row of the matrix
```

* Average matrix in an array
```{r}
a <- array(rnorm(2*2*10), c(2,2,10))
apply(a, c(1,2), mean)#Perserve dim 1&2
rowMeans(a,dims = 2)##Equal with `rowMeans`
```


## *lapply and sapply* with *swirl()*
* `cls_list <- lapply(flags, class)` will apply the `class()` function to each column of the flags dataset.  
* The following two are equivalent..(But `sapply` gives a named vector)
```{r}
missingHead <- c("name", "landmass", "zone", "area", "population", "language", "religion", "bars", "stripes", "colours", "red", "green", "blue", "gold", "white", "black", "orange", "mainhue", "circles", "crosses", "saltires", "quarters", "sunstars", "crescent", "triangle", "icon", "animate", "text", "topleft", "botright")
flags <- read.csv(file = "flag.data", header = FALSE)
colnames(flags) <- missingHead

as.character(lapply(flags, class))
sapply(flags, class)

```
```{r}
flag_colors <- flags[, 11:17]
head(flag_colors)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
```

* `unique` will return a list of unique elements  
```{r}
unique(c(3,4,5,5,5,6,6))
```


### mapply  
* Multivariate version of lapply  
* applies a function in parallel over a set of arguments
```{r}
str(mapply)
```
  + `FUN` is a function to apply  
  + `...` contains arguments to apply over  
  + `MoreArgs` is a list of other arguments to `FUN`.
  + `SIMPLIFY` indicates whether the result should be simplified  
  
*Following two are equal, but mapply is concise  
```{r}
list(rep(1, 4), rep(2,3), rep(3,2), rep(4,1))
mapply(rep, 1:4, 4:1)
```

* "Vectorizing" a function
```{r}
noise <- function(n, mean, sd) {
  rnorm(n,mean,sd)
}
noise(5,1,2)#Works as expected
noise(1:5,1:5, 2)#One would expect 1 rand with mean 1, 2 with mean 2, etc...
#One is to use mapply to generate the expected behavior
mapply(noise, 1:5, 1:5, 2)
```

### tapply
* Apply a function over subsets of a vector  
* Arguments..
```{r}
str(tapply)
```
  + `x` is a vector
  + `INDEX` is a factor or a list of factors (or else they are coerced to factors)  
  + `FUN` is a function to be applied  
  + `...` contains other arguments to be passed `FUN`  
  + `simplify`, should we simplify the result?

* Take group means
```{r}
x = c(rnorm(10), runif(10), rnorm(10,1))
factor <- gl(3, 10)
tapply(x, factor, mean)##apply the mean function to the subsets from factor in the x variable
```

* If you don't simplify you get back a list  
```{r}
tapply(x, factor, mean, simplify = FALSE)
```

* Can also calculate range
```{r}
tapply(x, factor, range)
```

### split  
* Useful in conjunction with `apply` functions.
* `split` takes a vector or other objects and splits it into groups determined by a factor or list of factors  
```{r}
str(split)
```
 + `x` is a vector (or list) or data frame  
 + `f` is a factor (or coerced to one) or a list of factors  
 + `drop` indicates whether empty factors levels should be dropped  
 
```{r}
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
split(x,f)
```

* A common idiom is `split` followed by an `lapply`.  
```{r}
lapply(split(x, f), mean)
```

```{r}
s <- split(airquality, airquality$Month)
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")], na.rm = TRUE))
##`na.rm = TRUE` gets rid of nas when calculating mean
```

* Splitting on More than one Level
```{r}
x <- rnorm(10)
f1 <- gl(2,5)
f2 <- gl(5, 2)
f1
f2
interaction(f1, f2) #Combines the levels
```

* Interactions can create empty levels  
```{r}
str(split(x, list(f1, f2)))
str(split(x, list(f1, f2), drop = TRUE))
```

* `drop` = TRUE takes care of empty levels  




## *vapply and tapply* with *swirl()*
## vapply  
* `vapply` allows you to specify the format of the result explicitly.
  + If the default doesn't match the format you specify it'll throw an error
  + Helpful when writing functions
```{r}
sapply(flags, class)#Implicitly returns a simplified result
vapply(flags, class, character(1))#Explicitly returns chars
```
  + faster than `sapply` in large datasets
    - sapply saves typing when doing analysis interactively (at the prompt)  

### tapply  
* `tapply` applies a function to each cell of an array, given by the levels of certain factors.  
* The following finds the freq. of animate images on flags, from the flags dataset used in the last `swirl()` section, with respect to each continent.  
```{r}
tapply(flags$animate, flags$landmass, mean)
```

* Or a stat summary of population (in millions) with respect to red being on the flag  
```{r}
tapply(flags$population, flags$red, summary)
```


## Debugging Tools  
* These tools come with R  


### Diagnosing the Problem
* Indications that something's not right
  + `message`: A generic notification/diagnostic message produced by the `message` function; execution of the function continues  
  + `warning`: An indication that something is wrong but **not necessarily fatal**; execution of the function continues, warning returns *after execution*; generated by the `warning` function  
```{r}
log(-1)
```
  
  + `error`: An indication that a fatal problem has occurred; execution stops; produced by the `stop` function  
  + `condition`: A generic concept for indicating that something unexpected can occur; all of the above are types of conditions; programmers can create their own conditions

* How to evaluate an error  
  + Identify your input and how a function was called  
  + Identify what you expected as an output, message, etc.  
  + Identify what you actual got as an output and how it differs from what you expected  
  + Question if your expectation themselves were correct  
  + See if you can exactly reproduce the problem as to verifying your understanding of the issue/error


### Basic Tools  

* Primary tools, these are interactive tools specifically designed to allow you to pick through a function. 
  + `traceback`: prints out the function call stack after an error occurs; does nothing if there's no error  
  + `debug`: flags a function for "debug" mode which allows you to step through execution of a function one line at a time  
    - Anytime the function is called it will suspend the run and open up a debug, which will go through the function line by line
  + `browser`: suspends the execution of a function wherever it is called and puts the function in debug mode  
    - Helpful to stop in the middle of a function
  + `trace`: allows you to inset debugging code into a function a specific places.  
    - Good when using other's code. Ussually just insert `browser`
  + `recover`: allows you to modify the error behavior so that you can browse the function call stack
    - Normally when you get an error, the execution of the function that threw it will stop and you'll get the error message to display and you're returned to the console, by default. Setting an error handler can change this behavior. `recover` is one of these *error handler*s.

### Using the Tools  
* Giving the traceback is helpful for communicating an error.  
* `traceback()` has to be called right after the error
  + Shows functions between code and where where an error occurred  
* `debug`
  + Hit `n` to run next line
  + Ex:  
    - `>debug(lm)`
    - `>lm(y ~ x)`
    - <Debug menu will open when lm is ran>
    
* `recover`
  + `options(error = recover)` will set a global option for the session so that whenever an error occurs a menu shows up, that is similar to `traceback`

* Summary
  + There are three main indications of a problem/condition: `message`, `warning`, `error`
    - only an `error` is fatal
  + When analyzing a function with a problem, make sure you can reproduce the problem, clearly state your expectations and how the output differs form your expectation.  
  + Interactive debugging tools `traceback`, `debug`, `browser`, `trace`, and `recover` can be used to find problematic code in functions
  + Debugging tools are not a substitute for thinking  
  

```{r}
ints <- seq(from = 1.75, length.out = 6, by = 1.5)
sleeptime <- strptime("08:00", "%H:%M")
sleeptime + (ints) * 3600
```











# Simulation & code profiling

### Learning Objectives  
* Call the  **[str function on an arbitrary R object.](#the-str-function)**  
* Describe the difference between the **["by.self"](#by.self)** and **["by.total"](#by.total)** output produced by the R profiler.
* Simulate a **[random normal variable](#rnorm)** with an arbitrary mean and standard deviation.  
* Simulate data from a **[normal linear model.](#linear-regression)**  
  
## The str Function  
**"Most useful function in `R`"**
* A diagnostic function and an alternative to `summary`  
* Good to display (abbrv.) contents of (possibly nested) lists.  
* Displays approx. one line per basic object  

```{r}
str(str) #A function( that takes an object, ...)
str(lm)#returns the args. for lm fn
x <- rnorm(100, 2, 4)
summary(x)# shows stats summary
str(x)#Shows what the data look like
f <-  gl(40, 10)##Factor with 40 levels, each is rep 10 times
str(f)##Gives some info on factor
summary(f)##Gives num of elements in each of 40 levels, not compact
library(datasets)
head(airquality)
str(airquality)
m <- matrix(rnorm(100), 10, 10)
str(m)
m[,-1]
##Create list of airquality split by month
s <- split(airquality, airquality$Month)
str(s)## gives a summary of nested dataframes
```
  

## Simulation - Generating Random Numbers  

* Simulation is important to reproduce results  
* Functions for simulating probability distributions in R  
  + `rnorm`: generate random Normal variate with a given mean and standard deviation  
  + `dnorm`: evaluate the Normal probability density (with a given mean/SD) at a point (or vector of points)  
  + `pnorm`: evaluate the cumulative distribution function for a Normal distribution  
  + `rpois`: generate random Poisson variates with a given rate.  
  
* Probability distribution functions are prefixed with a 
  + `d` for density  
  + `r` for random number generation  
  + `p` for cumulative distribution  
  + `q` for quantile function  

```{r}
n <- 100
x <- seq(from = 0, to = 1, length = n)
p <- sample(seq(from = 0, to = 1, length = 100000), size = n)
q <- sample(x)


dnorm(x, mean = 0, sd = 1, log = FALSE)
rnorm(n, mean = 0, sd = 1)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
```

* Always set the random number seed when conducting a simulation
```{r}
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)#Will be same as first rnorm
```

* Generating Poisson data

```{r}
rpois(10, 1)## 10 vars with rate of 1
rpois(10, 2)
rpois(10, 20)
ppois(2, 2) ## Cumulative distribution
ppois(4,2)## Pr(x <= 4) with rate of 2
ppois(6,2)## Pr(x <= 6) with rate of 2
```

## Simulation - Simulating a Linear Model  
* Suppose we want to simulate from the following linear model:
$$y = B~0~ + B~1~x + E$$
where $$E ~ N(0,2)$$, Assume $$x ~ N(0,1)$$, $$B~0~ = 0.5$$ and $$B~1~ = 2$$.  

```{r}
set.seed(20)
x <- rnorm(100)# default mean = 0, sd = 2
e <- rnorm(100, 0, 2) #mean = 0, sd = 2
y <- 0.5 + 2 + x + e
summary(y)
plot(x,y)
```

* Simulating a Poisson model where:
  + Y ~ Poisson(mu)
  +log(mu) = $$B~0~ + B~1~x$$  
  +$$B~0~ = 0.5$$ and $$B~1~ = 0.3$$. 
* We need to use the `rpois` function for this  
```{r}
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x,y)
```
   


## Simulation - Random Sampling  
* `sample` function
  + Allows you to draw randomly from a set
  + `sample(1:10, 4)` will sample 4 random numbers between 1 and 10 without replacement
```{r}
set.seed(1)
sample(1:10, 4)
sample(1:10, 4)
sample(letters, 5)
sample(1:10) ## permutation
sample(1:10)
sample(1:10, replace = TRUE) ## with replacement
```
  
* Summary  
  + Drawing samples from specific probability distribution ns can be done with `r*` functions  
  + Standard distributions are built in: Normal, Poisson, Binomial, Exponential, Gamma, etc.  
  + The `sample` function can be used to draw random samples from arbitrary vectors  
  + Setting the random number generator seed via set.seed is critical for reproducibility

## *Looking at Data* in `swirl()`  
* When first working with a new dataset, the first thing you should do is look at it!
  + What is the format?
  + What are the dimensions?  
  + What are the variable names?  
  + How are the variables stored?  
  + Are there missing data?  
  + Are there any flaws in the data?  
* This lesson will be using a dataset constructed from the United States Department of Agriculture's PLANTS Database to show off some ways to look at data  

```{r}
plants <- dget("plants.R")
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)#Make a table based on a factor
str(plants)##One of the "best" to use
```


## *Simulation* in `swirl()`  
* This section focuses on the r*** functions for prob. distributions in R  

* `sample()`
  + Simulate rolling four six-sided dice:
```{r}
sample(1:6, 4, replace = TRUE)
```
  
  + Simulate flipping an unfair coin 100 times
```{r}
flips <- sample(c(0,1), 100, replace = TRUE, c(0.3, 0.7))
sum(flips) #Num of heads
```
  
* `rbinom()`
  + Performs a random binomial sample  
  + Demonstrating unfair coin simulation with `rbinorm`
    - This will return the number of successes(`1`s)  
```{r}
rbinom(1, size = 100, prob = 0.7)
```
  
* `rnorm()`
  + std. normal distribution
```{r}
rnorm(10)
rnorm(10, 100, 25)#Default can be changed too
```
  
* `rpois()`
  + Poisson distribution
```{r}
rpois(n = 5, 10)#mean = 10/(time int)
```
  
* `hist()`
  + Histogram function

* All of the standard probability distributions are built into R, including...
  + `rexp()` - exponential  
  + `rchisq()` - chi-squared  
  + `rgamma()` - gamma
  


## R Profiler  
### Pt. 1  
* Helps you figure out why a program is taking so much time and suggests strats for fixing the problem. 
* Profiling is a systematic way to examine how much time is spent in different parts of a program  
* Useful when trying to optimize your code  
* Profiling is better than guessing when trying to analyze a project
  
* One should not think of optimization first. You should focus on getting the code to run and be understandable.
  + "*We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.*"  *--Donald Knuth*  
  + Difficult to figure out where your program is spending most of it's time without having the program all together.    
* *So.. You want optimize your code...*
  + Remember, you are a scientist. Collect data first,
  + collect said data with **profiling**
    
### Using system.time()  
* Takes an arbitrary R expression as input (can be wrapped in curly braces) and returns the amount of time take to evalue the expression  
* Comuptes the time (in seconds) needed toe xecute an expression
  + If there's an error, it'll return time 'til the error occured.  
* Returns an object of class `proc_time`
  + **user time**: time charged to the CPU(s) for this expression (Time the computer experiences) 
  + **elapsed time**: "wall clock" time (Time the user experiences)
* Usually, the two times are relatively close  
  + Elapsed time may be *greater than* user time if the CPU spends a lot of time waiting around for external events to happen.  
  
```{r}
system.time(readLines("http://www.jhsph.edu"))
```
  
  
  + Elapsed time may be *smaller than* the user time fi your machine has multiple cores/processors (and is capable of using them)  
    - Multi-threaded BLAS libraries (vecLib/Accelerate, ATLAS, ACML, MKL)  
    - Parallel processing via the **parallel** package  
    
```{r}
hilbert <- function(n) {
  i <- 1:n
  1 / outer(i - 1, i, "+")
}

x <- hilbert(1000)
system.time(svd(x))
```

* Testing a whole expression:  
```{r}
system.time({
  n <- 1000
  r <- numeric(n)
  for(i in 1:n) {
    x <- rnorm(n)
    r[i] <- mean(x)
  }
})
```

* `system.time()` allow syou to test cetrain functions or code blocks  
  + So this is assuming that you know where to look. 
  + Pt. 2 will cover what to do if you don't know where to start    
  
  


### Pt. 2, Using Rprof()
* `Rprof()` function starts the profiler in R
  + R must be compiled with profiler support (but this is usually the case)
  +  You should not use both `Rprof()` and `system.time()` together 
  + If your code runs very quickly, the profiler is not useful; however you probably don't need it in that case   
  
* `summaryRprof()` function summarizes the output from `Rprof()` 
  + keeps track of the function call stack at regualrly sampled intervals and tabulates how much time is spent in each function
  + Default sampling interval is 0.02 seconds  
  
  + There are two methdos for normalizing the data  
    - "by.total" divides the time spent in each function by the total run time  
    - "by.self" does the same but first subtracts out time spent in fucntions above in the call stack  
    
### Using "by total" and "by self"  
* `by.total`  
  + normalizes by total time spent in a function.
    - so by.total reports how much time is spent in top level function, ussually just calling to helper functions
  
* `by.self`  
  + tells you how much time is being taken in a given function after subtracting out lower level functions

* C or Fortran code is not profiled



## *Base Graphics* in `swirl()`  
* One of the greatest strengths of R is the ease with which it can create publication0quality graphics.  
```{r}
data(cars)
head(cars)
plot(cars)
```

* R always trys to output somemthing sensible, as such `plot(cars)` assumes you want the two columns plotted against eachother  
* Below R uses the argument names in the first example, then the second corrects this  

```{r}
plot(cars$speed, cars$dist)
plot(cars$speed, cars$dist, 
     xlab = "Speed", ylab = "Stopping Distance", 
     main = "My Plot", sub = "My Plot Subtitle")
```

* Limit x range
```{r}
plot(cars, xlim = (c(10,15)))
plot(cars, pch = 2)##Triangles
plot(cars, col = 2)##Color is red
```

* `boxplot()`
```{r}
data(mtcars)
boxplot(formula = mpg ~ cyl, data = mtcars)
```
  
* Histograms
```{r}
hist(mtcars$mpg)
```


### Scribbles from quiz  
```{r}
##1
set.seed(1)
rpois(5,2)
```

```{r}
##5
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10,0,20)
y <- 0.5 + 2 * x + e
```









